"""
–ö—Ä–∏—Å—Ç–∏–Ω–∞ 7.2 ‚Äî Knowledge Distillation (–î–∏—Å—Ç–∏–ª–ª—è—Ü–∏—è –∑–Ω–∞–Ω–∏–π)

–ó–ê–ß–ï–ú:
  –ö–æ–≥–¥–∞ LLM —Ä–µ—à–∞–µ—Ç –∑–∞–¥–∞—á—É, –ö—Ä–∏—Å—Ç–∏–Ω–∞ –∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç –Ω–µ —Ç–æ–ª—å–∫–æ –û–¢–í–ï–¢,
  –Ω–æ –∏ –ü–†–û–¶–ï–°–° –†–ê–°–°–£–ñ–î–ï–ù–ò–Ø. –≠—Ç–æ –∫–ª—é—á–µ–≤–æ–µ –æ—Ç–ª–∏—á–∏–µ –æ—Ç –ø—Ä–æ—Å—Ç–æ–≥–æ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è.

  LLM: "–ß—Ç–æ–±—ã —Å–æ–∑–¥–∞—Ç—å CSV-–ø–∞—Ä—Å–µ—Ä:
        1) –æ—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª
        2) —Ä–∞–∑–±–∏—Ç—å –ø–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—é
        3) –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∏
        4) –∏—Ç–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–∏"

  –ö—Ä–∏—Å—Ç–∏–Ω–∞ –∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç –®–ê–ë–õ–û–ù —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è:
  "–ß—Ç–æ–±—ã —Å–æ–∑–¥–∞—Ç—å [X]-–ø–∞—Ä—Å–µ—Ä:
   1) –æ—Ç–∫—Ä—ã—Ç—å [–∏—Å—Ç–æ—á–Ω–∏–∫]
   2) —Ä–∞–∑–±–∏—Ç—å –ø–æ [—Ñ–æ—Ä–º–∞—Ç—É]
   3) –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å [–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ]
   4) –∏—Ç–µ—Ä–∏—Ä–æ–≤–∞—Ç—å [—ç–ª–µ–º–µ–Ω—Ç—ã]"

  –í —Å–ª–µ–¥—É—é—â–∏–π —Ä–∞–∑ –¥–ª—è "—Å–æ–∑–¥–∞–π JSON-–ø–∞—Ä—Å–µ—Ä" ‚Äî –ö—Ä–∏—Å—Ç–∏–Ω–∞ –°–ê–ú–ê
  –ø—Ä–∏–º–µ–Ω—è–µ—Ç —à–∞–±–ª–æ–Ω: –æ—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª ‚Üí —Ä–∞–∑–±–∏—Ç—å –ø–æ JSON ‚Üí ...

–ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ ReasoningChain                              ‚îÇ
  ‚îÇ   steps: [ThoughtStep, ThoughtStep, ...]    ‚îÇ
  ‚îÇ   intent: "create_parser"                   ‚îÇ
  ‚îÇ   variables: {X: "CSV", source: "—Ñ–∞–π–ª"}     ‚îÇ
  ‚îÇ   template: generalized chain               ‚îÇ
  ‚îÇ   confidence: 0.85                          ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

  ThoughtStep:
    thought:     "–ù—É–∂–Ω–æ –æ—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª"
    action:      "read_file"
    observation:  "–§–∞–π–ª –ø—Ä–æ—á–∏—Ç–∞–Ω, 100 —Å—Ç—Ä–æ–∫"
    conclusion:  "–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –ø–∞—Ä—Å–∏–Ω–≥—É"

–•–†–ê–ù–ï–ù–ò–ï:
  SQLite ‚Äî reasoning chains + templates
  FTS5 ‚Äî –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –ø–æ —Å–∏—Ç—É–∞—Ü–∏–∏

–û–ë–£–ß–ï–ù–ò–ï:
  1. LLM —Ä–µ—à–∞–µ—Ç –∑–∞–¥–∞—á—É ‚Üí –ø–∞—Ä—Å–∏–º chain-of-thought
  2. –û–±–æ–±—â–∞–µ–º: –∑–∞–º–µ–Ω—è–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
  3. –°–æ—Ö—Ä–∞–Ω—è–µ–º —à–∞–±–ª–æ–Ω
  4. –ü—Ä–∏ –ø–æ—Ö–æ–∂–µ–º –∑–∞–ø—Ä–æ—Å–µ: –Ω–∞—Ö–æ–¥–∏–º —à–∞–±–ª–æ–Ω ‚Üí –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
"""

import sqlite3
import json
import re
import time
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from collections import defaultdict

from utils.logging import get_logger
import config

logger = get_logger("knowledge_distillation")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#               –ü–ê–†–°–ò–ù–ì –¶–ï–ü–û–ß–ï–ö –†–ê–°–°–£–ñ–î–ï–ù–ò–ô
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —à–∞–≥–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ LLM
STEP_PATTERNS = [
    # –ù—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
    re.compile(r'^\s*(\d+)[.)]\s*(.+)', re.MULTILINE),
    # –ú–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
    re.compile(r'^\s*[-‚Ä¢*]\s*(.+)', re.MULTILINE),
    # "–®–∞–≥ N:" —Ñ–æ—Ä–º–∞—Ç
    re.compile(r'(?:—à–∞–≥|step)\s*(\d+)\s*[:.]\s*(.+)', re.IGNORECASE | re.MULTILINE),
    # "–°–Ω–∞—á–∞–ª–∞..., –∑–∞—Ç–µ–º..., –ø–æ—Ç–æ–º..."
    re.compile(r'(?:—Å–Ω–∞—á–∞–ª–∞|–ø–µ—Ä–≤—ã–º –¥–µ–ª–æ–º|–¥–ª—è –Ω–∞—á–∞–ª–∞)\s+(.+?)(?:\.|$)', re.IGNORECASE),
    re.compile(r'(?:–∑–∞—Ç–µ–º|–¥–∞–ª–µ–µ|–ø–æ—Ç–æ–º|–ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ)\s+(.+?)(?:\.|$)', re.IGNORECASE),
    re.compile(r'(?:–Ω–∞–∫–æ–Ω–µ—Ü|–≤ –∫–æ–Ω—Ü–µ|–≤ –∏—Ç–æ–≥–µ)\s+(.+?)(?:\.|$)', re.IGNORECASE),
]

# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–±–æ–±—â–µ–Ω–∏—è (–∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ ‚Üí –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è)
GENERALIZATION_PATTERNS = [
    # –ò–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ ‚Üí {filename}
    (re.compile(r'[\w\-]+\.\w{1,5}'), "{filename}"),
    # –ü—É—Ç–∏ ‚Üí {filepath}
    (re.compile(r'[/~][\w/\-.]+'), "{filepath}"),
    # –ß–∏—Å–ª–∞ ‚Üí {number}
    (re.compile(r'\b\d{2,}\b'), "{number}"),
    # URL ‚Üí {url}
    (re.compile(r'https?://\S+'), "{url}"),
    # –Ø–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è ‚Üí {language}
    (re.compile(
        r'\b(python|javascript|typescript|java|rust|go|ruby|'
        r'php|c\+\+|swift|kotlin)\b', re.I
    ), "{language}"),
]


class KnowledgeDistillation:
    """
    –î–∏—Å—Ç–∏–ª–ª—è—Ü–∏—è –∑–Ω–∞–Ω–∏–π –∏–∑ LLM ‚Äî —É—á–∏–º—Å—è –î–£–ú–ê–¢–¨, –∞ –Ω–µ –∑–∞–ø–æ–º–∏–Ω–∞—Ç—å.

    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ü–µ–ø–æ—á–∫–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π (chain-of-thought) –∏–∑ –æ—Ç–≤–µ—Ç–æ–≤ LLM
    –∏ –ø—Ä–∏–º–µ–Ω—è–µ—Ç –∏—Ö –∫ –Ω–æ–≤—ã–º –ø–æ—Ö–æ–∂–∏–º –∑–∞–¥–∞—á–∞–º.

    –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
        kd = KnowledgeDistillation()

        # 1. LLM –æ—Ç–≤–µ—Ç–∏–ª–∞ ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ
        kd.distill(
            user_input="–°–æ–∑–¥–∞–π CSV-–ø–∞—Ä—Å–µ—Ä –Ω–∞ Python",
            llm_response="–ß—Ç–æ–±—ã —Å–æ–∑–¥–∞—Ç—å CSV-–ø–∞—Ä—Å–µ—Ä:\n1) –û—Ç–∫—Ä–æ–µ–º —Ñ–∞–π–ª...",
            intent="create_code",
            result_success=True,
        )

        # 2. –ü–æ—Ö–æ–∂–∏–π –≤–æ–ø—Ä–æ—Å ‚Äî –∏—â–µ–º —à–∞–±–ª–æ–Ω
        chain = kd.find_reasoning("–°–æ–∑–¥–∞–π JSON-–ø–∞—Ä—Å–µ—Ä")
        if chain:
            # –ï—Å—Ç—å —à–∞–±–ª–æ–Ω! –ü—Ä–∏–º–µ–Ω—è–µ–º —Å –Ω–æ–≤—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏
            steps = chain["steps"]
            variables = chain["variables"]  # {format: "JSON"}

        # 3. –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å
        kd.feedback(chain["chain_id"], useful=True)
    """

    def __init__(self, sentence_embeddings=None, db_path: Path = None):
        self._sentence = sentence_embeddings
        self._db_path = db_path or (config.config.data_dir / "knowledge_distillation.db")
        self._db_path.parent.mkdir(parents=True, exist_ok=True)

        self._conn = sqlite3.connect(str(self._db_path))
        self._conn.row_factory = sqlite3.Row
        self._conn.execute("PRAGMA journal_mode=WAL")
        self._conn.execute("PRAGMA synchronous=NORMAL")

        self._create_tables()

        stats = self.get_stats()
        logger.info(
            f"üß™ KnowledgeDistillation: {stats['chains']} —Ü–µ–ø–æ—á–µ–∫, "
            f"{stats['templates']} —à–∞–±–ª–æ–Ω–æ–≤, "
            f"{stats['total_steps']} —à–∞–≥–æ–≤"
        )

    def _create_tables(self):
        cur = self._conn.cursor()

        # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–µ–ø–æ—á–∫–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
        cur.execute("""
            CREATE TABLE IF NOT EXISTS reasoning_chains (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_input TEXT NOT NULL,
                intent TEXT NOT NULL,
                keywords TEXT NOT NULL,
                steps_json TEXT NOT NULL,
                variables_json TEXT DEFAULT '{}',
                confidence REAL DEFAULT 1.0,
                successes INTEGER DEFAULT 1,
                failures INTEGER DEFAULT 0,
                created_at REAL NOT NULL,
                last_used REAL NOT NULL
            )
        """)

        # –û–±–æ–±—â—ë–Ω–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã (generalized templates)
        cur.execute("""
            CREATE TABLE IF NOT EXISTS reasoning_templates (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                intent_pattern TEXT NOT NULL,
                template_steps_json TEXT NOT NULL,
                variable_slots TEXT NOT NULL,
                example_inputs TEXT DEFAULT '[]',
                confidence REAL DEFAULT 1.0,
                usage_count INTEGER DEFAULT 0,
                created_at REAL NOT NULL,
                updated_at REAL NOT NULL
            )
        """)

        # FTS5 –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        cur.execute("""
            CREATE VIRTUAL TABLE IF NOT EXISTS chains_fts
            USING fts5(keywords, content=reasoning_chains, content_rowid=id)
        """)

        # –ò–Ω–¥–µ–∫—Å—ã
        cur.execute("CREATE INDEX IF NOT EXISTS idx_chains_intent ON reasoning_chains(intent)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_chains_conf ON reasoning_chains(confidence DESC)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_templates_intent ON reasoning_templates(intent_pattern)")

        self._conn.commit()

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    #               –î–ò–°–¢–ò–õ–õ–Ø–¶–ò–Ø (—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def distill(
        self,
        user_input: str,
        llm_response: str,
        intent: str,
        result_success: bool = True,
        extra_context: Dict = None,
    ) -> Optional[int]:
        """
        –î–∏—Å—Ç–∏–ª–ª–∏—Ä—É–µ—Ç –∑–Ω–∞–Ω–∏—è –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM.

        1. –ü–∞—Ä—Å–∏—Ç —Ü–µ–ø–æ—á–∫—É —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–∞
        2. –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        3. –°–æ–∑–¥–∞—ë—Ç –æ–±–æ–±—â—ë–Ω–Ω—ã–π —à–∞–±–ª–æ–Ω
        4. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ –ë–î

        Returns:
            chain_id –∏–ª–∏ None (–µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è)
        """
        # 1. –ü–∞—Ä—Å–∏–º —à–∞–≥–∏ –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM
        steps = self._parse_reasoning_steps(llm_response)
        if not steps:
            return None

        # 2. –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
        variables = self._extract_variables(user_input, llm_response)

        # 3. –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        keywords = self._extract_keywords(user_input)

        # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é —Ü–µ–ø–æ—á–∫—É
        now = time.time()
        cur = self._conn.cursor()
        cur.execute("""
            INSERT INTO reasoning_chains
            (user_input, intent, keywords, steps_json, variables_json,
             confidence, created_at, last_used)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            user_input, intent, keywords,
            json.dumps(steps, ensure_ascii=False),
            json.dumps(variables, ensure_ascii=False),
            1.0 if result_success else 0.5,
            now, now,
        ))
        chain_id = cur.lastrowid

        # –û–±–Ω–æ–≤–ª—è–µ–º FTS
        cur.execute("""
            INSERT INTO chains_fts (rowid, keywords) VALUES (?, ?)
        """, (chain_id, keywords))

        # 5. –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–∑–¥–∞—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å –æ–±–æ–±—â—ë–Ω–Ω—ã–π —à–∞–±–ª–æ–Ω
        self._update_template(intent, steps, variables, user_input)

        self._conn.commit()

        logger.debug(
            f"üß™ Distilled: '{user_input[:50]}' ‚Üí {len(steps)} steps, "
            f"{len(variables)} vars, chain_id={chain_id}"
        )

        return chain_id

    def _parse_reasoning_steps(self, text: str) -> List[Dict]:
        """
        –ü–∞—Ä—Å–∏—Ç —Ü–µ–ø–æ—á–∫—É —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–∞ LLM.

        –†–∞—Å–ø–æ–∑–Ω–∞—ë—Ç —Ñ–æ—Ä–º–∞—Ç—ã:
        - –ù—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ (1. 2. 3.)
        - –ú–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ (- ‚Ä¢ *)
        - "–®–∞–≥ N:" —Ñ–æ—Ä–º–∞—Ç
        - "–°–Ω–∞—á–∞–ª–∞..., –∑–∞—Ç–µ–º..., –ø–æ—Ç–æ–º..."
        """
        steps = []

        # –ü—Ä–æ–±—É–µ–º –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫
        numbered = re.findall(
            r'^\s*(\d+)[.)]\s*(.+?)$', text, re.MULTILINE
        )
        if len(numbered) >= 2:
            for num, step_text in numbered:
                steps.append({
                    "step": int(num),
                    "text": step_text.strip(),
                    "type": "action",
                })
            return steps

        # –ü—Ä–æ–±—É–µ–º –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫
        bulleted = re.findall(
            r'^\s*[-‚Ä¢*]\s*(.+?)$', text, re.MULTILINE
        )
        if len(bulleted) >= 2:
            for i, step_text in enumerate(bulleted, 1):
                steps.append({
                    "step": i,
                    "text": step_text.strip(),
                    "type": "action",
                })
            return steps

        # –ü—Ä–æ–±—É–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã
        sequential_markers = [
            (r'(?:—Å–Ω–∞—á–∞–ª–∞|–ø–µ—Ä–≤—ã–º –¥–µ–ª–æ–º|–¥–ª—è –Ω–∞—á–∞–ª–∞)\s+(.+?)(?:\.|,|;|$)', "first"),
            (r'(?:–∑–∞—Ç–µ–º|–¥–∞–ª–µ–µ|–ø–æ—Ç–æ–º|–ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ|–ø–æ—Å–ª–µ)\s+(.+?)(?:\.|,|;|$)', "then"),
            (r'(?:–Ω–∞–∫–æ–Ω–µ—Ü|–≤ –∫–æ–Ω—Ü–µ|–≤ –∏—Ç–æ–≥–µ|–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ)\s+(.+?)(?:\.|$)', "finally"),
        ]

        step_num = 0
        for pattern, step_type in sequential_markers:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                step_num += 1
                steps.append({
                    "step": step_num,
                    "text": match.strip(),
                    "type": step_type,
                })

        if len(steps) >= 2:
            return steps

        # Fallback: —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º (–µ—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–æ–≥–∏—á–µ—Å–∫–∏–µ —à–∞–≥–∏)
        sentences = re.split(r'[.!]\s+', text)
        action_sentences = [
            s.strip() for s in sentences
            if len(s.strip()) > 10 and any(
                kw in s.lower() for kw in
                ["–Ω—É–∂–Ω–æ", "–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ", "—Å–ª–µ–¥—É–µ—Ç", "–º–æ–∂–Ω–æ", "–Ω–∞–¥–æ",
                 "—Å–æ–∑–¥–∞–π", "–æ—Ç–∫—Ä–æ–π", "–∑–∞–ø—É—Å—Ç–∏", "–Ω–∞–π–¥–∏", "–ø—Ä–æ–≤–µ—Ä—å"]
            )
        ]

        if len(action_sentences) >= 2:
            for i, sent in enumerate(action_sentences[:10], 1):
                steps.append({
                    "step": i,
                    "text": sent,
                    "type": "action",
                })
            return steps

        return []

    def _extract_variables(self, user_input: str, llm_response: str) -> Dict[str, str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è) –∏–∑ –∑–∞–ø—Ä–æ—Å–∞"""
        variables = {}

        # –ò–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤
        files = re.findall(r'([\w\-]+\.\w{1,5})', user_input)
        for i, f in enumerate(files):
            key = "filename" if i == 0 else f"filename_{i+1}"
            variables[key] = f

        # –ü—É—Ç–∏
        paths = re.findall(r'([/~][\w/\-.]+)', user_input)
        for i, p in enumerate(paths):
            key = "filepath" if i == 0 else f"filepath_{i+1}"
            variables[key] = p

        # –Ø–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è
        langs = re.findall(
            r'\b(python|javascript|typescript|java|rust|go|ruby|'
            r'php|c\+\+|swift|kotlin)\b', user_input, re.I
        )
        if langs:
            variables["language"] = langs[0].lower()

        # –ö–ª—é—á–µ–≤—ã–µ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ (–ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞)
        words = user_input.lower().split()
        stop = {
            "—Å–æ–∑–¥–∞–π", "—Å–¥–µ–ª–∞–π", "–Ω–∞–ø–∏—à–∏", "–Ω–∞–π–¥–∏", "–ø–æ–∫–∞–∂–∏",
            "—Ñ–∞–π–ª", "–ø–∞–ø–∫—É", "–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ", "–¥–ª—è", "–Ω–∞", "–≤", "—Å",
            "–∫–∞–∫", "—á—Ç–æ", "—ç—Ç–æ", "–Ω—É–∂–Ω–æ", "–º–æ–∂–Ω–æ", "–ø–æ–∂–∞–ª—É–π—Å—Ç–∞",
        }
        meaningful = [w for w in words if w not in stop and len(w) > 3]
        if meaningful:
            variables["topic"] = meaningful[0]

        return variables

    def _extract_keywords(self, text: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è FTS5"""
        stop_words = {
            "—è", "—Ç—ã", "–æ–Ω", "–æ–Ω–∞", "–º—ã", "–≤—ã", "–æ–Ω–∏",
            "–≤", "–Ω–∞", "–∏", "—Å", "–ø–æ", "–æ—Ç", "–∫", "–Ω–µ",
            "—á—Ç–æ", "—ç—Ç–æ", "–∫–∞–∫", "–Ω–æ", "–∞", "–∏–ª–∏", "–¥–∞", "–Ω–µ—Ç",
            "–º–æ–∂–µ—à—å", "–ø–æ–∂–∞–ª—É–π—Å—Ç–∞", "–º–Ω–µ", "–¥–ª—è", "–º–µ–Ω—è",
        }
        words = re.findall(r'[–∞-—è—ëa-z0-9]+', text.lower())
        keywords = [w for w in words if len(w) > 2 and w not in stop_words]
        return " ".join(keywords[:15])

    def _update_template(
        self,
        intent: str,
        steps: List[Dict],
        variables: Dict[str, str],
        user_input: str,
    ):
        """–°–æ–∑–¥–∞—ë—Ç –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –æ–±–æ–±—â—ë–Ω–Ω—ã–π —à–∞–±–ª–æ–Ω"""
        # –û–±–æ–±—â–∞–µ–º —à–∞–≥–∏: –∑–∞–º–µ–Ω—è–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ {variable}
        template_steps = []
        for step in steps:
            text = step["text"]
            for var_name, var_value in variables.items():
                if var_value in text:
                    text = text.replace(var_value, "{" + var_name + "}")
            template_steps.append({
                "step": step["step"],
                "text": text,
                "type": step.get("type", "action"),
            })

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º: –µ—Å—Ç—å –ª–∏ —É–∂–µ —à–∞–±–ª–æ–Ω –¥–ª—è —ç—Ç–æ–≥–æ intent?
        existing = self._conn.execute("""
            SELECT id, example_inputs FROM reasoning_templates
            WHERE intent_pattern = ?
            ORDER BY usage_count DESC LIMIT 1
        """, (intent,)).fetchone()

        now = time.time()
        variable_slots = json.dumps(list(variables.keys()), ensure_ascii=False)

        if existing:
            # –û–±–Ω–æ–≤–ª—è–µ–º: –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä
            examples = json.loads(existing["example_inputs"])
            if user_input not in examples:
                examples.append(user_input)
                examples = examples[-20:]  # –•—Ä–∞–Ω–∏–º –º–∞–∫—Å–∏–º—É–º 20 –ø—Ä–∏–º–µ—Ä–æ–≤

            self._conn.execute("""
                UPDATE reasoning_templates
                SET example_inputs = ?, usage_count = usage_count + 1, updated_at = ?
                WHERE id = ?
            """, (json.dumps(examples, ensure_ascii=False), now, existing["id"]))
        else:
            # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π —à–∞–±–ª–æ–Ω
            self._conn.execute("""
                INSERT INTO reasoning_templates
                (intent_pattern, template_steps_json, variable_slots,
                 example_inputs, created_at, updated_at)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (
                intent,
                json.dumps(template_steps, ensure_ascii=False),
                variable_slots,
                json.dumps([user_input], ensure_ascii=False),
                now, now,
            ))

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    #               –ü–û–ò–°–ö –†–ê–°–°–£–ñ–î–ï–ù–ò–ô
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def find_reasoning(
        self,
        user_input: str,
        intent: str = None,
        min_confidence: float = 0.6,
    ) -> Optional[Dict]:
        """
        –ò—â–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â—É—é —Ü–µ–ø–æ—á–∫—É —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞.

        1. –ü–æ–∏—Å–∫ –ø–æ FTS5 (–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞)
        2. –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ confidence + similarity
        3. –ü–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–æ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö

        Returns:
            Dict —Å –ø–æ–ª—è–º–∏:
            - chain_id: int
            - steps: List[Dict]
            - variables: Dict
            - confidence: float
            - source: "exact" | "template"
            –ò–ª–∏ None –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏
        """
        keywords = self._extract_keywords(user_input)
        if not keywords:
            return None

        # 1. –ü–æ–∏—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ü–µ–ø–æ—á–∫–∏ —á–µ—Ä–µ–∑ FTS5
        try:
            rows = self._conn.execute("""
                SELECT rc.id, rc.user_input, rc.intent, rc.steps_json,
                       rc.variables_json, rc.confidence, rc.successes, rc.failures
                FROM chains_fts
                JOIN reasoning_chains rc ON chains_fts.rowid = rc.id
                WHERE chains_fts MATCH ?
                AND rc.confidence >= ?
                ORDER BY chains_fts.rank
                LIMIT 5
            """, (keywords, min_confidence)).fetchall()
        except Exception:
            rows = []

        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ intent –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
        if intent and rows:
            filtered = [r for r in rows if r["intent"] == intent]
            if filtered:
                rows = filtered

        if rows:
            # –†–∞–Ω–∂–∏—Ä—É–µ–º
            best = max(rows, key=lambda r: (
                r["confidence"] * (r["successes"] / (r["failures"] + 1))
            ))

            # –û–±–Ω–æ–≤–ª—è–µ–º last_used
            self._conn.execute(
                "UPDATE reasoning_chains SET last_used = ? WHERE id = ?",
                (time.time(), best["id"])
            )
            self._conn.commit()

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ —Ç–µ–∫—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            new_variables = self._extract_variables(user_input, "")
            old_variables = json.loads(best["variables_json"])

            # –ü–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ —à–∞–≥–∏
            steps = json.loads(best["steps_json"])
            adapted_steps = self._adapt_steps(steps, old_variables, new_variables)

            return {
                "chain_id": best["id"],
                "steps": adapted_steps,
                "variables": new_variables,
                "original_variables": old_variables,
                "confidence": best["confidence"],
                "source": "exact",
            }

        # 2. –ü–æ–∏—Å–∫ –ø–æ —à–∞–±–ª–æ–Ω–∞–º
        return self._find_by_template(user_input, intent, min_confidence)

    def _find_by_template(
        self,
        user_input: str,
        intent: str = None,
        min_confidence: float = 0.6,
    ) -> Optional[Dict]:
        """–ò—â–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏–π —à–∞–±–ª–æ–Ω —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π"""
        query = "SELECT * FROM reasoning_templates WHERE confidence >= ?"
        params: list = [min_confidence]

        if intent:
            query += " AND intent_pattern = ?"
            params.append(intent)

        query += " ORDER BY usage_count DESC LIMIT 10"
        templates = self._conn.execute(query, params).fetchall()

        if not templates:
            return None

        # –ï—Å–ª–∏ –µ—Å—Ç—å sentence_embeddings ‚Äî –∏—â–µ–º –ø–æ —Å—Ö–æ–¥—Å—Ç–≤—É
        if self._sentence:
            best_template = None
            best_sim = 0.0

            for tpl in templates:
                examples = json.loads(tpl["example_inputs"])
                for example in examples:
                    sim = self._sentence.similarity(user_input, example)
                    if sim > best_sim:
                        best_sim = sim
                        best_template = tpl

            if best_template and best_sim >= 0.5:
                new_variables = self._extract_variables(user_input, "")
                steps = json.loads(best_template["template_steps_json"])
                adapted = self._adapt_template_steps(steps, new_variables)

                return {
                    "chain_id": best_template["id"],
                    "steps": adapted,
                    "variables": new_variables,
                    "confidence": best_sim * best_template["confidence"],
                    "source": "template",
                }
        else:
            # –ë–µ–∑ sentence_embeddings ‚Äî –±–µ—Ä—ë–º –ø–µ—Ä–≤—ã–π –ø–æ–¥—Ö–æ–¥—è—â–∏–π
            if templates:
                tpl = templates[0]
                new_variables = self._extract_variables(user_input, "")
                steps = json.loads(tpl["template_steps_json"])
                adapted = self._adapt_template_steps(steps, new_variables)

                return {
                    "chain_id": tpl["id"],
                    "steps": adapted,
                    "variables": new_variables,
                    "confidence": tpl["confidence"] * 0.5,
                    "source": "template",
                }

        return None

    def _adapt_steps(
        self,
        steps: List[Dict],
        old_vars: Dict[str, str],
        new_vars: Dict[str, str],
    ) -> List[Dict]:
        """–ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —à–∞–≥–∏: –∑–∞–º–µ–Ω—è–µ—Ç —Å—Ç–∞—Ä—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –Ω–∞ –Ω–æ–≤—ã–µ"""
        adapted = []
        for step in steps:
            text = step["text"]
            for var_name in old_vars:
                old_val = old_vars[var_name]
                new_val = new_vars.get(var_name, old_val)
                text = text.replace(old_val, new_val)
            adapted.append({**step, "text": text})
        return adapted

    def _adapt_template_steps(
        self,
        template_steps: List[Dict],
        variables: Dict[str, str],
    ) -> List[Dict]:
        """–ü–æ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ —à–∞–±–ª–æ–Ω–Ω—ã–µ —à–∞–≥–∏"""
        adapted = []
        for step in template_steps:
            text = step["text"]
            for var_name, var_value in variables.items():
                text = text.replace("{" + var_name + "}", var_value)
            adapted.append({**step, "text": text})
        return adapted

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    #               –û–ë–†–ê–¢–ù–ê–Ø –°–í–Ø–ó–¨
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def feedback(self, chain_id: int, useful: bool, source: str = "exact"):
        """
        –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å: –±—ã–ª–∞ –ª–∏ —Ü–µ–ø–æ—á–∫–∞ –ø–æ–ª–µ–∑–Ω–∞.

        useful=True  ‚Üí —É—Å–∏–ª–∏–≤–∞–µ–º (confidence += 0.05)
        useful=False ‚Üí –æ—Å–ª–∞–±–ª—è–µ–º (confidence -= 0.15)
        """
        if source == "exact":
            table = "reasoning_chains"
        else:
            table = "reasoning_templates"

        if useful:
            self._conn.execute(f"""
                UPDATE {table}
                SET successes = successes + 1,
                    confidence = MIN(1.0, confidence + 0.05)
                WHERE id = ?
            """, (chain_id,))
        else:
            self._conn.execute(f"""
                UPDATE {table}
                SET failures = failures + 1,
                    confidence = MAX(0.0, confidence - 0.15)
                WHERE id = ?
            """, (chain_id,))

        self._conn.commit()

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    #               –°–¢–ê–¢–ò–°–¢–ò–ö–ê
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def get_stats(self) -> Dict:
        chains = self._conn.execute(
            "SELECT COUNT(*) as c FROM reasoning_chains"
        ).fetchone()["c"]

        templates = self._conn.execute(
            "SELECT COUNT(*) as c FROM reasoning_templates"
        ).fetchone()["c"]

        total_steps = 0
        rows = self._conn.execute(
            "SELECT steps_json FROM reasoning_chains"
        ).fetchall()
        for row in rows:
            try:
                steps = json.loads(row["steps_json"])
                total_steps += len(steps)
            except (json.JSONDecodeError, TypeError):
                pass

        strong_chains = self._conn.execute(
            "SELECT COUNT(*) as c FROM reasoning_chains WHERE confidence >= 0.8"
        ).fetchone()["c"]

        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ intent-—ã
        intents = self._conn.execute(
            "SELECT DISTINCT intent FROM reasoning_chains"
        ).fetchall()

        return {
            "chains": chains,
            "templates": templates,
            "total_steps": total_steps,
            "strong_chains": strong_chains,
            "intents": [r["intent"] for r in intents],
        }

    def get_reasoning_report(self) -> str:
        """–û—Ç—á—ë—Ç –æ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã—Ö –∑–Ω–∞–Ω–∏—è—Ö"""
        stats = self.get_stats()
        report = "–î–∏—Å—Ç–∏–ª–ª—è—Ü–∏—è –∑–Ω–∞–Ω–∏–π:\n"
        report += f"  –¶–µ–ø–æ—á–∫–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π: {stats['chains']}\n"
        report += f"  –û–±–æ–±—â—ë–Ω–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã: {stats['templates']}\n"
        report += f"  –í—Å–µ–≥–æ —à–∞–≥–æ–≤: {stats['total_steps']}\n"
        report += f"  –°–∏–ª—å–Ω—ã–µ (conf‚â•0.8): {stats['strong_chains']}\n"
        report += f"  Intent-—ã: {', '.join(stats['intents']) or '–Ω–µ—Ç'}\n"
        return report

    def cleanup(self, min_confidence: float = 0.2, max_age_days: int = 60):
        """–£–¥–∞–ª—è–µ—Ç —Å–ª–∞–±—ã–µ –∏ —Å—Ç–∞—Ä—ã–µ —Ü–µ–ø–æ—á–∫–∏"""
        cutoff = time.time() - (max_age_days * 86400)

        self._conn.execute("""
            DELETE FROM reasoning_chains
            WHERE confidence < ? AND last_used < ?
        """, (min_confidence, cutoff))

        # –ü–µ—Ä–µ—Å—Ç—Ä–∞–∏–≤–∞–µ–º FTS
        try:
            self._conn.execute("INSERT INTO chains_fts(chains_fts) VALUES('rebuild')")
        except Exception:
            pass

        self._conn.commit()
        logger.info("üßπ Knowledge distillation: weak chains cleaned up")

    def close(self):
        self._conn.commit()
        self._conn.close()
