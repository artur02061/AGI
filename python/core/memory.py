"""
–ö—Ä–∏—Å—Ç–∏–Ω–∞ 6.0 ‚Äî –°–∏—Å—Ç–µ–º–∞ –ø–∞–º—è—Ç–∏

–ò–ó–ú–ï–ù–ï–ù–ò–Ø v6.0:
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å MemorySummarizer (–∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è)
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å KnowledgeGraph (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å)
- –ü–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º —É—Ä–æ–≤–Ω—è–º: raw ‚Üí daily ‚Üí weekly ‚Üí monthly ‚Üí knowledge graph
- get_relevant_context –∏—â–µ—Ç –í–°–ï —ç–ø–∏–∑–æ–¥—ã (–Ω–µ —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 50)
- Auto-summarize –ø—Ä–∏ save()
"""

import json
import asyncio
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional

from utils.logging import get_logger
import config

logger = get_logger("memory")


class MemorySystem:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é —Å –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–µ–π"""

    def __init__(self):
        self.working = []
        self.episodic = []
        self.semantic = {}

        # –§–∞–π–ª—ã
        self.episodic_file = config.EPISODIC_MEMORY_FILE
        self.semantic_file = config.SEMANTIC_MEMORY_FILE

        # v6.0: –°—É–º–º–∞—Ä–∏–∑–∞—Ç–æ—Ä –∏ Knowledge Graph (–ª–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è)
        self._summarizer = None
        self._knowledge_graph = None

        self.load()

        logger.info(f"–ü–∞–º—è—Ç—å: {len(self.episodic)} —ç–ø–∏–∑–æ–¥–æ–≤")

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    #          –õ–ï–ù–ò–í–ê–Ø –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –¢–Ø–ñ–Å–õ–´–• –ö–û–ú–ü–û–ù–ï–ù–¢–û–í
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    @property
    def summarizer(self):
        """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ç–æ—Ä–∞"""
        if self._summarizer is None:
            try:
                from modules.memory.summarizer import MemorySummarizer
                self._summarizer = MemorySummarizer()
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –°—É–º–º–∞—Ä–∏–∑–∞—Ç–æ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        return self._summarizer

    @property
    def knowledge_graph(self):
        """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Knowledge Graph"""
        if self._knowledge_graph is None:
            try:
                from modules.memory.knowledge_graph import KnowledgeGraph
                self._knowledge_graph = KnowledgeGraph()
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Knowledge Graph –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        return self._knowledge_graph

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    #                    –†–ê–ë–û–ß–ê–Ø –ü–ê–ú–Ø–¢–¨
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def add_to_working(self, role: str, content: str):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –≤ —Ä–∞–±–æ—á—É—é –ø–∞–º—è—Ç—å"""
        self.working.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        })

        if len(self.working) > config.WORKING_MEMORY_SIZE:
            self.working.pop(0)

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    #                  –≠–ü–ò–ó–û–î–ò–ß–ï–°–ö–ê–Ø –ü–ê–ú–Ø–¢–¨
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def add_episode(
        self,
        user_input: str,
        response: str,
        emotion: str,
        importance: int = 1
    ):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —ç–ø–∏–∑–æ–¥"""
        episode = {
            "timestamp": datetime.now().isoformat(),
            "user_input": user_input,
            "response": response,
            "emotion": emotion,
            "importance": importance
        }

        self.episodic.append(episode)

        # v6.0: –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∞–∫—Ç—ã –≤ Knowledge Graph (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ, fire-and-forget)
        if self.knowledge_graph and importance >= config.config.knowledge_graph_min_importance:
            try:
                try:
                    asyncio.get_running_loop()
                    asyncio.create_task(
                        self.knowledge_graph.extract_and_add(user_input, response, importance)
                    )
                except RuntimeError:
                    # No running loop ‚Äî sync fallback
                    triples = self.knowledge_graph._regex_extract(user_input)
                    for s, p, o in triples:
                        self.knowledge_graph.add_triple(s, p, o, importance, "regex")
            except Exception as e:
                logger.debug(f"KG extraction skipped: {e}")

        # –†–æ—Ç–∞—Ü–∏—è
        if len(self.episodic) > config.MAX_EPISODIC_MEMORY:
            self.episodic.sort(key=lambda x: x['importance'])
            self.episodic = self.episodic[100:]

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    #              –ü–û–ò–°–ö –ö–û–ù–¢–ï–ö–°–¢–ê (–ú–ù–û–ì–û–£–†–û–í–ù–ï–í–´–ô)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def get_relevant_context(self, query: str, max_items: int = 3) -> str:
        """
        v6.0: –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –ø–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

        1. Raw episodes (–≤—Å–µ, –Ω–µ —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 50!)
        2. Knowledge Graph —Ñ–∞–∫—Ç—ã
        3. Summary —Å–∞–º–º–∞—Ä–∏ (daily/weekly/monthly)
        """
        parts = []

        # ‚îÄ‚îÄ 1. Raw episodes (keyword search –ø–æ –í–°–ï–ú) ‚îÄ‚îÄ
        episode_results = self._search_episodes(query, max_items)
        if episode_results:
            for score, episode in episode_results:
                date = episode['timestamp'][:10]
                user_preview = episode['user_input'][:80]
                parts.append(f"[{date}] –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_preview}")

        # ‚îÄ‚îÄ 2. Knowledge Graph ‚îÄ‚îÄ
        if self.knowledge_graph:
            kg_context = self.knowledge_graph.get_context_for_query(query, max_facts=3)
            if kg_context:
                parts.append(kg_context)

        # ‚îÄ‚îÄ 3. Summary search (–µ—Å–ª–∏ raw –Ω–µ –¥–∞–ª –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ) ‚îÄ‚îÄ
        if len(parts) < max_items and self.summarizer:
            summary_results = self.summarizer.search_summaries(query, max_results=2)
            for r in summary_results:
                level = r["level"]
                key = r["key"]
                summary = r["summary"][:150]
                parts.append(f"[{level} {key}] {summary}")

        if not parts:
            return "–ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."

        return "\n".join(parts)

    def _search_episodes(self, query: str, max_items: int = 3) -> List:
        """Keyword search –ø–æ –í–°–ï–ú —ç–ø–∏–∑–æ–¥–∞–º (–Ω–µ —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º 50)"""
        if not self.episodic:
            return []

        query_words = set(w.lower() for w in query.split() if len(w) > 2)
        if not query_words:
            return []

        scored = []
        for episode in self.episodic:
            text = episode['user_input'] + " " + episode['response']
            text_words = set(w.lower() for w in text.split() if len(w) > 2)

            intersection = len(query_words & text_words)
            if intersection > 0:
                score = intersection * episode.get('importance', 1)
                scored.append((score, episode))

        scored.sort(reverse=True, key=lambda x: x[0])
        return scored[:max_items]

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    #                  –ü–ï–†–°–ò–°–¢–ï–ù–¢–ù–û–°–¢–¨
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def save(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–∞–º—è—Ç—å + –∑–∞–ø—É—Å–∫–∞–µ—Ç auto-summarize"""
        try:
            # –≠–ø–∏–∑–æ–¥–∏—á–µ—Å–∫–∞—è
            with open(self.episodic_file, 'w', encoding='utf-8') as f:
                json.dump(self.episodic, f, ensure_ascii=False, indent=2)

            # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è
            with open(self.semantic_file, 'w', encoding='utf-8') as f:
                json.dump(self.semantic, f, ensure_ascii=False, indent=2)

            # v6.0: Knowledge Graph
            if self.knowledge_graph:
                self.knowledge_graph.save()

            # v6.0: Auto-summarize
            if self.summarizer and config.config.memory_summarize_enabled:
                try:
                    asyncio.get_running_loop()
                    asyncio.create_task(self._auto_summarize())
                except RuntimeError:
                    # –ù–µ—Ç event loop ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                    pass

            logger.info("üíæ –ü–∞–º—è—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–∞–º—è—Ç–∏: {e}")

    async def _auto_summarize(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Å—Ç–∞—Ä—ã—Ö —ç–ø–∏–∑–æ–¥–æ–≤"""
        if self.summarizer:
            try:
                self.episodic = await self.summarizer.auto_summarize(self.episodic)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ auto-summarize: {e}")

    def load(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–∞–º—è—Ç—å"""
        try:
            if self.episodic_file.exists():
                with open(self.episodic_file, 'r', encoding='utf-8') as f:
                    self.episodic = json.load(f)

            if self.semantic_file.exists():
                with open(self.semantic_file, 'r', encoding='utf-8') as f:
                    self.semantic = json.load(f)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–∞–º—è—Ç–∏: {e}")

    def clear_working(self):
        """–û—á–∏—â–∞–µ—Ç —Ä–∞–±–æ—á—É—é –ø–∞–º—è—Ç—å"""
        self.working.clear()
        logger.info("–†–∞–±–æ—á–∞—è –ø–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞")

    def get_stats(self) -> Dict[str, int]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞–º—è—Ç–∏"""
        stats = {
            "working": len(self.working),
            "episodic": len(self.episodic),
            "semantic_keys": len(self.semantic),
        }

        if self.summarizer:
            stats["summaries"] = self.summarizer.get_stats()

        if self.knowledge_graph:
            stats["knowledge_graph"] = self.knowledge_graph.get_stats()

        return stats
