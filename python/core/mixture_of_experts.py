"""
ĞšÑ€Ğ¸ÑÑ‚Ğ¸Ğ½Ğ° 7.3 â€” Mixture of Experts (Ğ¡Ğ¼ĞµÑÑŒ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ²)

Ğ—ĞĞ§Ğ•Ğœ:
  ĞĞ´Ğ¸Ğ½ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€ Ğ·Ğ½Ğ°ĞµÑ‚ Ğ²ÑÑ‘ Ğ¿Ğ¾Ğ²ĞµÑ€Ñ…Ğ½Ğ¾ÑÑ‚Ğ½Ğ¾.
  ĞĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ ĞœĞĞ›Ğ•ĞĞ¬ĞšĞ˜Ğ¥ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ¾Ğ²-ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸ÑÑ‚Ğ¾Ğ² Ğ·Ğ½Ğ°ÑÑ‚ ÑĞ²Ğ¾Ñ Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ÑŒ Ğ“Ğ›Ğ£Ğ‘ĞĞšĞ.

  Router Ñ€ĞµÑˆĞ°ĞµÑ‚, ĞºĞ°ĞºĞ¾Ğ¼Ñƒ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ñƒ Ğ¾Ñ‚Ğ´Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ:

    "ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸" â†’ Expert: CODE (90%) + GENERAL (10%)
    "ĞšĞ°Ğº Ğ´ĞµĞ»Ğ°?"                 â†’ Expert: CHAT (95%)
    "ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ"     â†’ Expert: ANALYSIS (80%) + CODE (20%)

ĞĞ Ğ¥Ğ˜Ğ¢Ğ•ĞšĞ¢Ğ£Ğ Ğ:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Input: "ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸"          â”‚
  â”‚         â†“                                    â”‚
  â”‚ Sentence Embedding â†’ [d_model]               â”‚
  â”‚         â†“                                    â”‚
  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
  â”‚ â”‚   Router (MLP)  â”‚ â†’ [0.9, 0.02, 0.08, ...]â”‚
  â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                          â”‚
  â”‚      â†“       â†“                               â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
  â”‚  â”‚Expert 1â”‚ â”‚Expert 2â”‚  (top-K=2 Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ…)   â”‚
  â”‚  â”‚ CODE   â”‚ â”‚GENERAL â”‚                       â”‚
  â”‚  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                       â”‚
  â”‚      â†“          â†“                            â”‚
  â”‚  0.9 Ã— out1 + 0.1 Ã— out2  (weighted merge)  â”‚
  â”‚         â†“                                    â”‚
  â”‚  Final output                                â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ğ­ĞšĞ¡ĞŸĞ•Ğ Ğ¢Ğ«:
  ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ ÑĞºÑĞ¿ĞµÑ€Ñ‚ â€” ÑÑ‚Ğ¾ Ğ›ĞĞ“ĞšĞ˜Ğ™ FFN (Feed-Forward Network):
  - d_model â†’ d_expert â†’ d_model
  - Ğ¡Ğ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ Ğ½Ğ° ÑĞ²Ğ¾Ñ‘Ğ¼ Ñ‚Ğ¸Ğ¿Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
  - ĞĞ±ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞºĞ¾Ğ³Ğ´Ğ° Router ĞµĞ³Ğ¾ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ¸Ñ€ÑƒĞµÑ‚

  ĞĞ• Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€! Ğ­ĞºÑĞ¿ĞµÑ€Ñ‚Ñ‹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ ĞºĞ°Ğº Ğ¡ĞŸĞ•Ğ¦Ğ˜ĞĞ›Ğ˜Ğ—Ğ˜Ğ ĞĞ’ĞĞĞĞ«Ğ™ FFN-ÑĞ»Ğ¾Ğ¹
  Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ MicroTransformer pipeline.

LOAD BALANCING:
  Ğ‘ĞµĞ· Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ¸ Router Ğ¼Ğ¾Ğ¶ĞµÑ‚ ÑÑ…Ğ»Ğ¾Ğ¿Ğ½ÑƒÑ‚ÑŒÑÑ Ğº 1 ÑĞºÑĞ¿ĞµÑ€Ñ‚Ñƒ.
  Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ auxiliary loss: ÑˆÑ‚Ñ€Ğ°Ñ„ Ğ·Ğ° Ğ½ĞµÑ€Ğ°Ğ²Ğ½Ğ¾Ğ¼ĞµÑ€Ğ½ÑƒÑ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºÑƒ.
"""

import json
import math
import random
import sqlite3
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field

from utils.logging import get_logger
import config

logger = get_logger("mixture_of_experts")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#               ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

NUM_EXPERTS = 6         # ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ²
TOP_K_EXPERTS = 2       # Ğ¡ĞºĞ¾Ğ»ÑŒĞºĞ¾ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ² Ğ°ĞºÑ‚Ğ¸Ğ²Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ Ğ½Ğ° Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
D_EXPERT = 256          # Ğ¡ĞºÑ€Ñ‹Ñ‚Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ°
D_MODEL = 128           # Ğ Ğ°Ğ·Ğ¼ĞµÑ€Ğ½Ğ¾ÑÑ‚ÑŒ Ğ²Ñ…Ğ¾Ğ´Ğ°/Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ° (== MicroTransformer d_model)
BALANCE_COEFF = 0.01    # ĞšĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚ load balancing loss
ROUTER_LR = 1e-3        # Learning rate Ğ´Ğ»Ñ Router

# Ğ˜Ğ¼ĞµĞ½Ğ° ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ² (ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ)
EXPERT_NAMES = [
    "chat",       # ĞĞ±Ñ‰ĞµĞ½Ğ¸Ğµ, Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ñ, small talk
    "code",       # ĞŸÑ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ, Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ñ‹
    "analysis",   # ĞĞ½Ğ°Ğ»Ğ¸Ğ·, ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ, Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
    "creative",   # Ğ¢Ğ²Ğ¾Ñ€Ñ‡ĞµÑÑ‚Ğ²Ğ¾, Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ‚ĞµĞºÑÑ‚Ğ°
    "system",     # Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸, ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹
    "knowledge",  # Ğ¤Ğ°ĞºÑ‚Ñ‹, Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ñ, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ
]

# ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ° Ğ´Ğ»Ñ Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ (Ğ´Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Router)
EXPERT_KEYWORDS = {
    "chat": ["Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚", "ĞºĞ°Ğº Ğ´ĞµĞ»Ğ°", "Ğ·Ğ´Ñ€Ğ°Ğ²ÑÑ‚Ğ²ÑƒĞ¹", "Ğ¿Ğ¾ĞºĞ°", "ÑĞ¿Ğ°ÑĞ¸Ğ±Ğ¾",
             "Ğ´Ğ¾Ğ±Ñ€Ğ¾Ğµ ÑƒÑ‚Ñ€Ğ¾", "Ğ´Ğ¾Ğ±Ñ€Ñ‹Ğ¹ Ğ²ĞµÑ‡ĞµÑ€", "ĞºĞ°Ğº Ñ‚Ñ‹"],
    "code": ["ĞºĞ¾Ğ´", "python", "Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ", "ĞºĞ»Ğ°ÑÑ", "Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ°", "ÑĞºÑ€Ğ¸Ğ¿Ñ‚",
             "Ğ±Ğ°Ğ³", "Ğ¾ÑˆĞ¸Ğ±ĞºĞ°", "api", "git", "Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼", "ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ°",
             "Ñ€ĞµĞºÑƒÑ€ÑĞ¸Ñ", "Ğ¼Ğ°ÑÑĞ¸Ğ²", "Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ", "Ñ†Ğ¸ĞºĞ»"],
    "analysis": ["Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·", "ÑÑ€Ğ°Ğ²Ğ½Ğ¸", "ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°", "Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ", "Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚",
                 "Ñ‚Ñ€ĞµĞ½Ğ´", "Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°", "Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚", "Ğ³Ñ€Ğ°Ñ„Ğ¸Ğº"],
    "creative": ["Ğ½Ğ°Ğ¿Ğ¸ÑˆĞ¸ ÑÑ‚Ğ¸Ñ…", "Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ", "ÑĞºĞ°Ğ·ĞºĞ°", "Ğ¿Ñ€Ğ¸Ğ´ÑƒĞ¼Ğ°Ğ¹",
                 "Ñ„Ğ°Ğ½Ñ‚Ğ°Ğ·Ğ¸Ñ", "Ñ€Ğ°ÑÑĞºĞ°Ğ·", "Ğ¿Ğ¾ÑĞ¼Ğ°", "Ğ¿ĞµÑĞ½Ñ"],
    "system": ["Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸", "ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸", "Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹", "Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ°Ğ»", "ÑĞµÑ€Ğ²ĞµÑ€",
               "docker", "Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ", "Ñ„Ğ°Ğ¹Ğ»", "Ğ¿Ğ°Ğ¿ĞºĞ°", "ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°"],
    "knowledge": ["Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸", "Ñ€Ğ°ÑÑĞºĞ°Ğ¶Ğ¸", "Ñ‡Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ", "Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ", "Ğ·Ğ°Ñ‡ĞµĞ¼",
                  "ĞºĞ°Ğº Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚", "Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ", "Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿"],
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#               Ğ’Ğ¡ĞŸĞĞœĞĞ“ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ«Ğ• Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _zeros(n: int) -> List[float]:
    return [0.0] * n

def _randn(n: int, scale: float = 0.02) -> List[float]:
    return [random.gauss(0, scale) for _ in range(n)]

def _randn_matrix(rows: int, cols: int, scale: float = 0.02) -> List[List[float]]:
    return [_randn(cols, scale) for _ in range(rows)]

def _dot(a: List[float], b: List[float]) -> float:
    return sum(x * y for x, y in zip(a, b))

def _matvec(mat: List[List[float]], vec: List[float]) -> List[float]:
    return [_dot(row, vec) for row in mat]

def _relu(x: List[float]) -> List[float]:
    return [max(0.0, v) for v in x]

def _softmax(x: List[float]) -> List[float]:
    max_x = max(x) if x else 0.0
    exp_x = [math.exp(v - max_x) for v in x]
    s = sum(exp_x) + 1e-10
    return [v / s for v in exp_x]

def _vec_add(a: List[float], b: List[float]) -> List[float]:
    return [x + y for x, y in zip(a, b)]

def _vec_scale(a: List[float], s: float) -> List[float]:
    return [x * s for x in a]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#               EXPERT (FFN-ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸ÑÑ‚)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class Expert:
    """
    ĞĞ´Ğ¸Ğ½ ÑĞºÑĞ¿ĞµÑ€Ñ‚ â€” Ğ´Ğ²ÑƒÑ…ÑĞ»Ğ¾Ğ¹Ğ½Ñ‹Ğ¹ FFN:
      input [d_model] â†’ W1 â†’ ReLU â†’ W2 â†’ output [d_model]

    ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ ÑĞºÑĞ¿ĞµÑ€Ñ‚ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ Ğ½Ğ° ÑĞ²Ğ¾Ñ‘Ğ¼ Ñ‚Ğ¸Ğ¿Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡.
    """

    def __init__(self, name: str, d_model: int = D_MODEL, d_expert: int = D_EXPERT):
        self.name = name
        self.d_model = d_model
        self.d_expert = d_expert

        # Weights
        scale = math.sqrt(2.0 / d_model)  # He init
        self.W1 = _randn_matrix(d_expert, d_model, scale)
        self.b1 = _zeros(d_expert)
        self.W2 = _randn_matrix(d_model, d_expert, math.sqrt(2.0 / d_expert))
        self.b2 = _zeros(d_model)

        # Stats
        self.activations = 0
        self.total_weight = 0.0

    def forward(self, x: List[float]) -> List[float]:
        """
        Forward pass: x [d_model] â†’ output [d_model]
        """
        # Layer 1: x @ W1.T + b1 â†’ ReLU
        hidden = _matvec(self.W1, x)
        hidden = _vec_add(hidden, self.b1)
        hidden = _relu(hidden)

        # Layer 2: hidden @ W2.T + b2
        output = _matvec(self.W2, hidden)
        output = _vec_add(output, self.b2)

        return output

    def get_params(self) -> Dict:
        return {
            "W1": self.W1, "b1": self.b1,
            "W2": self.W2, "b2": self.b2,
        }

    def load_params(self, data: Dict):
        if "W1" in data and len(data["W1"]) == self.d_expert:
            self.W1 = data["W1"]
            self.b1 = data["b1"]
            self.W2 = data["W2"]
            self.b2 = data["b2"]

    def param_count(self) -> int:
        return (self.d_model * self.d_expert + self.d_expert +
                self.d_expert * self.d_model + self.d_model)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#               ROUTER (ĞœĞ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class Router:
    """
    Router: Ñ€ĞµÑˆĞ°ĞµÑ‚, ĞºĞ°ĞºĞ¸Ñ… ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ² Ğ°ĞºÑ‚Ğ¸Ğ²Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ.

    input [d_model] â†’ W_router â†’ softmax â†’ gate weights [num_experts]

    Top-K gating: Ğ°ĞºÑ‚Ğ¸Ğ²Ğ¸Ñ€ÑƒÑÑ‚ÑÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ K ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ² Ñ Ğ½Ğ°Ğ¸Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼Ğ¸ Ğ²ĞµÑĞ°Ğ¼Ğ¸.
    ĞÑÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ = 0 (sparse activation Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸).
    """

    def __init__(
        self,
        d_model: int = D_MODEL,
        num_experts: int = NUM_EXPERTS,
        top_k: int = TOP_K_EXPERTS,
    ):
        self.d_model = d_model
        self.num_experts = num_experts
        self.top_k = top_k

        # Router weights: d_model â†’ num_experts
        scale = math.sqrt(1.0 / d_model)
        self.W_gate = _randn_matrix(num_experts, d_model, scale)
        self.b_gate = _zeros(num_experts)

        # Noise for exploration (Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°ĞµÑ‚ Ğ½Ğµ Ğ·Ğ°ÑÑ‚Ñ€ÑÑ‚ÑŒ Ğ½Ğ° 1 ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğµ)
        self._noise_scale = 0.1

        # Stats per expert
        self._routing_counts = [0] * num_experts

    def route(
        self,
        x: List[float],
        training: bool = False,
    ) -> List[Tuple[int, float]]:
        """
        ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ top-K ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ² Ğ¸ Ğ¸Ñ… Ğ²ĞµÑĞ°.

        Args:
            x: input vector [d_model]
            training: ĞµÑĞ»Ğ¸ True, Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ noise Ğ´Ğ»Ñ exploration

        Returns:
            [(expert_idx, gate_weight), ...] â€” top-K ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ²
        """
        # Logits: x @ W_gate.T + b
        logits = _matvec(self.W_gate, x)
        logits = _vec_add(logits, self.b_gate)

        # Add noise during training
        if training and self._noise_scale > 0:
            noise = _randn(self.num_experts, self._noise_scale)
            logits = _vec_add(logits, noise)

        # Softmax Ğ´Ğ»Ñ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ĞµĞ¹
        probs = _softmax(logits)

        # Top-K selection
        indexed = [(i, p) for i, p in enumerate(probs)]
        indexed.sort(key=lambda x: x[1], reverse=True)
        top_k = indexed[:self.top_k]

        # Re-normalize top-K weights
        total = sum(w for _, w in top_k) + 1e-10
        top_k = [(idx, w / total) for idx, w in top_k]

        # Track routing counts
        for idx, _ in top_k:
            self._routing_counts[idx] += 1

        return top_k

    def compute_balance_loss(self) -> float:
        """
        Auxiliary loss: ÑˆÑ‚Ñ€Ğ°Ñ„ÑƒĞµÑ‚ Ğ·Ğ° Ğ½ĞµÑ€Ğ°Ğ²Ğ½Ğ¾Ğ¼ĞµÑ€Ğ½ÑƒÑ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºÑƒ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ².

        Ğ˜Ğ´ĞµĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ°: ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ ÑĞºÑĞ¿ĞµÑ€Ñ‚ = 1/num_experts Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ².
        """
        total = sum(self._routing_counts) + 1e-10
        fractions = [c / total for c in self._routing_counts]
        ideal = 1.0 / self.num_experts

        # CV (coefficient of variation) ĞºĞ°Ğº Ğ¼ĞµÑ€Ğ° Ğ´Ğ¸ÑĞ±Ğ°Ğ»Ğ°Ğ½ÑĞ°
        variance = sum((f - ideal) ** 2 for f in fractions) / self.num_experts
        balance_loss = variance * self.num_experts * BALANCE_COEFF

        return balance_loss

    def get_params(self) -> Dict:
        return {"W_gate": self.W_gate, "b_gate": self.b_gate}

    def load_params(self, data: Dict):
        if "W_gate" in data and len(data["W_gate"]) == self.num_experts:
            self.W_gate = data["W_gate"]
            self.b_gate = data["b_gate"]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#               MIXTURE OF EXPERTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class MixtureOfExperts:
    """
    Mixture of Experts: Router + Ğ½Ğ°Ğ±Ğ¾Ñ€ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… FFN-ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ².

    Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:
        moe = MixtureOfExperts()

        # ĞœĞ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ + Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°
        output, routing = moe.forward(input_vec)
        # output: [d_model], routing: [(expert_idx, weight), ...]

        # ĞœĞ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ Ñ‚ĞµĞºÑÑ‚Ñƒ (Ñ keyword fallback)
        output, routing = moe.process_text(
            text="ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸",
            input_vec=embedding,
        )

        # ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ (Ñ gradient from output)
        moe.train_step(input_vec, target_vec)
    """

    def __init__(
        self,
        d_model: int = D_MODEL,
        d_expert: int = D_EXPERT,
        num_experts: int = NUM_EXPERTS,
        top_k: int = TOP_K_EXPERTS,
        db_path: Path = None,
    ):
        self.d_model = d_model
        self.num_experts = num_experts
        self.top_k = top_k

        # Router
        self.router = Router(d_model, num_experts, top_k)

        # Experts
        self.experts: List[Expert] = []
        for i in range(num_experts):
            name = EXPERT_NAMES[i] if i < len(EXPERT_NAMES) else f"expert_{i}"
            self.experts.append(Expert(name, d_model, d_expert))

        # Persistence
        self._db_path = db_path or (config.config.data_dir / "mixture_of_experts.db")
        self._db_path.parent.mkdir(parents=True, exist_ok=True)
        self._conn = sqlite3.connect(str(self._db_path))
        self._conn.execute("PRAGMA journal_mode=WAL")
        self._create_tables()

        # Stats
        self._total_forwards = 0
        self._total_trains = 0
        self._load_state()

        total_params = self._count_params()
        logger.info(
            f"ğŸ§  MoE: {num_experts} experts Ã— {d_expert}d, "
            f"top-{top_k}, {total_params:,} params, "
            f"{self._total_forwards} forwards"
        )

    def _create_tables(self):
        self._conn.execute("""
            CREATE TABLE IF NOT EXISTS moe_state (
                key TEXT PRIMARY KEY,
                value TEXT NOT NULL
            )
        """)
        self._conn.commit()

    def _count_params(self) -> int:
        # Router
        count = self.d_model * self.num_experts + self.num_experts
        # Experts
        for expert in self.experts:
            count += expert.param_count()
        return count

    def _load_state(self):
        row = self._conn.execute(
            "SELECT value FROM moe_state WHERE key = 'model_data'"
        ).fetchone()
        if row:
            try:
                data = json.loads(row[0])
                self._total_forwards = data.get("total_forwards", 0)
                self._total_trains = data.get("total_trains", 0)
                if "router" in data:
                    self.router.load_params(data["router"])
                if "experts" in data:
                    for i, expert_data in enumerate(data["experts"]):
                        if i < len(self.experts):
                            self.experts[i].load_params(expert_data)
            except (json.JSONDecodeError, TypeError):
                pass

    def _save_state(self):
        data = {
            "total_forwards": self._total_forwards,
            "total_trains": self._total_trains,
            "router": self.router.get_params(),
            "experts": [e.get_params() for e in self.experts],
        }
        json_str = json.dumps(data)
        self._conn.execute("""
            INSERT INTO moe_state (key, value) VALUES ('model_data', ?)
            ON CONFLICT(key) DO UPDATE SET value = ?
        """, (json_str, json_str))
        self._conn.commit()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #           FORWARD PASS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def forward(
        self,
        x: List[float],
        training: bool = False,
    ) -> Tuple[List[float], List[Tuple[int, float]]]:
        """
        MoE forward pass.

        1. Router Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ top-K ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ²
        2. ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ ÑĞºÑĞ¿ĞµÑ€Ñ‚ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ²Ñ…Ğ¾Ğ´
        3. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ²Ğ·Ğ²ĞµÑˆĞµĞ½Ğ½Ğ¾ ÑÑƒĞ¼Ğ¼Ğ¸Ñ€ÑƒÑÑ‚ÑÑ

        Args:
            x: input [d_model]
            training: add noise to router

        Returns:
            (output [d_model], routing [(expert_idx, weight)])
        """
        # 1. Route
        routing = self.router.route(x, training=training)

        # 2. Forward through active experts
        output = _zeros(self.d_model)

        for expert_idx, gate_weight in routing:
            expert = self.experts[expert_idx]
            expert_output = expert.forward(x)

            # Weighted accumulation
            for i in range(self.d_model):
                output[i] += expert_output[i] * gate_weight

            # Track
            expert.activations += 1
            expert.total_weight += gate_weight

        self._total_forwards += 1

        # 3. Residual connection
        output = _vec_add(output, x)

        return output, routing

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #           TEXT-LEVEL INTERFACE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def process_text(
        self,
        text: str,
        input_vec: List[float],
        training: bool = False,
    ) -> Tuple[List[float], List[Tuple[int, float]]]:
        """
        ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ñ‚ĞµĞºÑÑ‚ Ñ‡ĞµÑ€ĞµĞ· MoE Ñ keyword-based routing hint.

        Ğ”Ğ»Ñ Ğ¿ĞµÑ€Ğ²Ñ‹Ñ… N Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² (Ğ¿Ğ¾ĞºĞ° Router Ğ½Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½) Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚
        keyword bias Ğº Router logits.
        """
        # Keyword-based bias (Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°ĞµÑ‚ Router Ğ½Ğ° ÑÑ‚Ğ°Ñ€Ñ‚Ğµ)
        keyword_bias = self._compute_keyword_bias(text)

        if keyword_bias and self._total_trains < 200:
            # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ bias Ğº Router gate logits
            orig_b = list(self.router.b_gate)
            for i, bias in enumerate(keyword_bias):
                if i < len(self.router.b_gate):
                    self.router.b_gate[i] += bias * max(0, 1.0 - self._total_trains / 200)

            output, routing = self.forward(input_vec, training=training)

            # Restore
            self.router.b_gate = orig_b
        else:
            output, routing = self.forward(input_vec, training=training)

        return output, routing

    def _compute_keyword_bias(self, text: str) -> Optional[List[float]]:
        """Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµÑ‚ bias Ğ´Ğ»Ñ Router Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… ÑĞ»Ğ¾Ğ²"""
        text_lower = text.lower()
        bias = _zeros(self.num_experts)
        has_match = False

        for i, expert in enumerate(self.experts):
            keywords = EXPERT_KEYWORDS.get(expert.name, [])
            score = sum(1 for kw in keywords if kw in text_lower)
            if score > 0:
                bias[i] = score * 0.5  # ĞœÑĞ³ĞºĞ¸Ğ¹ bias
                has_match = True

        return bias if has_match else None

    def get_expert_for_text(self, text: str, input_vec: List[float]) -> str:
        """Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¸Ğ¼Ñ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ³Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ° Ğ´Ğ»Ñ Ñ‚ĞµĞºÑÑ‚Ğ°"""
        _, routing = self.process_text(text, input_vec)
        if routing:
            return self.experts[routing[0][0]].name
        return "unknown"

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #           ĞĞ‘Ğ£Ğ§Ğ•ĞĞ˜Ğ•
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def train_step(
        self,
        x: List[float],
        target: List[float],
        lr: float = ROUTER_LR,
    ) -> float:
        """
        ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ MoE: ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ² + Router.

        Gradient-free Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ (ÑĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğµ):
        1. Forward â†’ output
        2. ĞÑˆĞ¸Ğ±ĞºĞ° = output - target
        3. ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ²ĞµÑĞ° Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ² Ğ¿Ñ€Ğ¾Ğ¿Ğ¾Ñ€Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ¾ÑˆĞ¸Ğ±ĞºĞµ
        4. Router Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ÑÑ Ñ‡ĞµÑ€ĞµĞ· reward: Ğ»ÑƒÑ‡ÑˆĞµ Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ» â†’ reward

        Args:
            x: input [d_model]
            target: target output [d_model]
            lr: learning rate

        Returns:
            loss (MSE)
        """
        # Forward
        output, routing = self.forward(x, training=True)

        # Loss
        error = [output[i] - target[i] for i in range(self.d_model)]
        loss = sum(e * e for e in error) / self.d_model

        # Update active experts (gradient-free)
        for expert_idx, gate_weight in routing:
            expert = self.experts[expert_idx]
            self._update_expert(expert, x, error, lr * gate_weight)

        # Update router (reward-based)
        self._update_router(routing, loss, lr)

        self._total_trains += 1

        # Periodic save
        if self._total_trains % 50 == 0:
            self._save_state()

        return loss

    def _update_expert(
        self,
        expert: Expert,
        x: List[float],
        error: List[float],
        lr: float,
    ):
        """
        ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ Ğ²ĞµÑĞ° ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ° (ÑƒĞ¿Ñ€Ğ¾Ñ‰Ñ‘Ğ½Ğ½Ñ‹Ğ¹ gradient descent).

        Ğ”Ğ»Ñ FFN: output = W2 @ relu(W1 @ x + b1) + b2
        Gradient: dW2 â‰ˆ error @ hidden.T, dW1 â‰ˆ (W2.T @ error) âŠ™ relu'(h) @ x.T
        """
        # Forward to get hidden
        hidden_raw = _matvec(expert.W1, x)
        hidden_raw = _vec_add(hidden_raw, expert.b1)
        hidden = _relu(hidden_raw)

        # Update W2: -= lr * error @ hidden.T
        for i in range(expert.d_model):
            for j in range(expert.d_expert):
                expert.W2[i][j] -= lr * error[i] * hidden[j]
            expert.b2[i] -= lr * error[i]

        # Backprop through W2 â†’ hidden gradient
        hidden_grad = _zeros(expert.d_expert)
        for j in range(expert.d_expert):
            for i in range(expert.d_model):
                hidden_grad[j] += expert.W2[i][j] * error[i]

        # ReLU gradient
        for j in range(expert.d_expert):
            if hidden_raw[j] <= 0:
                hidden_grad[j] = 0.0

        # Update W1: -= lr * hidden_grad @ x.T
        for j in range(expert.d_expert):
            for k in range(expert.d_model):
                expert.W1[j][k] -= lr * hidden_grad[j] * x[k]
            expert.b1[j] -= lr * hidden_grad[j]

    def _update_router(
        self,
        routing: List[Tuple[int, float]],
        loss: float,
        lr: float,
    ):
        """
        ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ Router Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ loss.

        Reward signal: Ğ¼Ğ°Ğ»ĞµĞ½ÑŒĞºĞ¸Ğ¹ loss â†’ ÑƒÑĞ¸Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰ÑƒÑ Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ,
                       Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹ loss â†’ Ğ¾ÑĞ»Ğ°Ğ±Ğ»ÑĞµĞ¼.
        """
        # Reward = -loss (Ñ‡ĞµĞ¼ Ğ¼ĞµĞ½ÑŒÑˆĞµ loss, Ñ‚ĞµĞ¼ Ğ»ÑƒÑ‡ÑˆĞµ)
        reward = math.exp(-loss) - 0.5  # Ğ¦ĞµĞ½Ñ‚Ñ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ²Ğ¾ĞºÑ€ÑƒĞ³ 0

        for expert_idx, gate_weight in routing:
            # Ğ£ÑĞ¸Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼/Ğ¾ÑĞ»Ğ°Ğ±Ğ»ÑĞµĞ¼ Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
            adjustment = lr * reward * 0.1
            self.router.b_gate[expert_idx] += adjustment

        # Balance loss: ÑˆÑ‚Ñ€Ğ°Ñ„ÑƒĞµĞ¼ Ğ½ĞµÑ€Ğ°Ğ²Ğ½Ğ¾Ğ¼ĞµÑ€Ğ½Ğ¾ÑÑ‚ÑŒ
        balance_loss = self.router.compute_balance_loss()
        if balance_loss > 0.01:
            total = sum(self.router._routing_counts) + 1e-10
            ideal = total / self.num_experts
            for i in range(self.num_experts):
                excess = (self.router._routing_counts[i] - ideal) / total
                self.router.b_gate[i] -= lr * excess * BALANCE_COEFF

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #           STATISTICS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def get_stats(self) -> Dict:
        expert_stats = []
        for i, expert in enumerate(self.experts):
            expert_stats.append({
                "name": expert.name,
                "activations": expert.activations,
                "avg_weight": expert.total_weight / max(1, expert.activations),
            })

        # Sort by activations (most active first)
        expert_stats.sort(key=lambda x: x["activations"], reverse=True)

        total_routes = sum(self.router._routing_counts)
        routing_distribution = {}
        for i, count in enumerate(self.router._routing_counts):
            name = self.experts[i].name if i < len(self.experts) else f"expert_{i}"
            routing_distribution[name] = round(count / max(1, total_routes), 3)

        return {
            "total_forwards": self._total_forwards,
            "total_trains": self._total_trains,
            "num_experts": self.num_experts,
            "top_k": self.top_k,
            "experts": expert_stats,
            "routing_distribution": routing_distribution,
            "balance_loss": round(self.router.compute_balance_loss(), 6),
        }

    def close(self):
        self._save_state()
        self._conn.close()
