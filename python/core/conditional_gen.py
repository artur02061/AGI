"""
ĞšÑ€Ğ¸ÑÑ‚Ğ¸Ğ½Ğ° 7.3 â€” Conditional Generation (Ğ£ÑĞ»Ğ¾Ğ²Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ)

Ğ—ĞĞ§Ğ•Ğœ:
  ĞĞ´Ğ¸Ğ½ Ğ¸ Ñ‚Ğ¾Ñ‚ Ğ¶Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ â†’ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ğ£Ğ¡Ğ›ĞĞ’Ğ˜Ğ™:
  - Ğ¡Ñ‚Ğ¸Ğ»ÑŒ: Ñ„Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹, Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ñ‹Ğ¹, Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹
  - ĞĞ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ: Ñ€Ğ°Ğ´Ğ¾ÑÑ‚Ğ½Ğ¾Ğµ, Ğ½ĞµĞ¹Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ, ÑĞ¾Ñ‡ÑƒĞ²ÑÑ‚Ğ²ÑƒÑÑ‰ĞµĞµ
  - Ğ¢ĞµĞ¼Ğ°: ĞºĞ¾Ğ´, Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ, Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·
  - Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚: Ñ‚ĞµĞºÑÑ‚, ÑĞ¿Ğ¸ÑĞ¾Ğº, Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ğ¾

ĞšĞĞš Ğ ĞĞ‘ĞĞ¢ĞĞ•Ğ¢:
  Ğš Ğ²Ğ²Ğ¾Ğ´Ñƒ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ° Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑÑÑ‚ÑÑ Ğ£Ğ¡Ğ›ĞĞ’ĞĞ«Ğ• Ğ¢ĞĞšĞ•ĞĞ«:

    [STYLE:formal] [MOOD:happy] [TOPIC:code] ĞĞ±ÑŠÑÑĞ½Ğ¸ Ñ€ĞµĞºÑƒÑ€ÑĞ¸Ñ

  ĞœĞ¾Ğ´ĞµĞ»ÑŒ ÑƒÑ‡Ğ¸Ñ‚ÑÑ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ¾-Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¼Ñƒ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ğ¹.
  Ğ£ÑĞ»Ğ¾Ğ²Ğ½Ñ‹Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ â€” ÑÑ‚Ğ¾ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµĞ¼Ñ‹Ğµ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¸, Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¾Ñ‚ ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ñ.

ĞĞ Ğ¥Ğ˜Ğ¢Ğ•ĞšĞ¢Ğ£Ğ Ğ:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Ğ£ÑĞ»Ğ¾Ğ²Ğ¸Ñ:                                    â”‚
  â”‚   style=formal, mood=happy, topic=code       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ ConditionEncoder                            â”‚
  â”‚   â†’ condition_vec [d_model]                 â”‚
  â”‚   (Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµĞ¼Ñ‹Ğ¹ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³ Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ) â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ [cond_vec] + [token_1] + [token_2] + ...    â”‚
  â”‚              â†“                               â”‚
  â”‚ MicroTransformer â†’ generate()                â”‚
  â”‚              â†“                               â”‚
  â”‚ "Ğ ĞµĞºÑƒÑ€ÑĞ¸Ñ â€” ÑÑ‚Ğ¾ Ğ¿Ñ€Ğ¸Ñ‘Ğ¼..."                    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ĞĞ‘Ğ£Ğ§Ğ•ĞĞ˜Ğ•:
  ĞŸÑ€Ğ¸ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ â†’ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµĞ¼ Ñ Ğ½Ğ¸Ğ¼Ğ¸.
  Ğ¢Ğ°Ğº Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ÑĞ²ÑĞ·Ñ‹Ğ²Ğ°ĞµÑ‚: formal + code â†’ "Ğ ĞµĞºÑƒÑ€ÑĞ¸Ñ â€” ÑÑ‚Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´..."
                         casual + code â†’ "ĞÑƒ, Ñ€ĞµĞºÑƒÑ€ÑĞ¸Ñ ÑÑ‚Ğ¾ ĞºĞ¾Ğ³Ğ´Ğ°..."
"""

import json
import math
import random
import re
import time
import sqlite3
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field

from utils.logging import get_logger
import config

logger = get_logger("conditional_gen")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#               Ğ£Ğ¡Ğ›ĞĞ’Ğ˜Ğ¯ Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Ğ’ÑĞµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğµ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ Ğ¸ Ğ¸Ñ… Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ
CONDITIONS = {
    "style": {
        "formal": 0,       # Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ("Ğ ĞµĞºÑƒÑ€ÑĞ¸Ñ â€” ÑÑ‚Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´...")
        "casual": 1,       # Ğ Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ñ‹Ğ¹ ("ĞÑƒ, Ñ€ĞµĞºÑƒÑ€ÑĞ¸Ñ ÑÑ‚Ğ¾ ĞºĞ¾Ğ³Ğ´Ğ°...")
        "technical": 2,    # Ğ¢ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ("Ğ ĞµĞºÑƒÑ€ÑĞ¸Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ f(n) = ...")
        "friendly": 3,     # Ğ”Ñ€ÑƒĞ¶ĞµĞ»ÑĞ±Ğ½Ñ‹Ğ¹ ("ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! Ğ ĞµĞºÑƒÑ€ÑĞ¸Ñ â€” ÑÑ‚Ğ¾...")
    },
    "mood": {
        "neutral": 0,      # ĞĞµĞ¹Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ
        "happy": 1,        # Ğ Ğ°Ğ´Ğ¾ÑÑ‚Ğ½Ğ¾Ğµ
        "empathetic": 2,   # Ğ¡Ğ¾Ñ‡ÑƒĞ²ÑÑ‚Ğ²ÑƒÑÑ‰ĞµĞµ
        "enthusiastic": 3, # Ğ’Ğ¾Ğ¾Ğ´ÑƒÑˆĞµĞ²Ğ»Ñ‘Ğ½Ğ½Ğ¾Ğµ
    },
    "topic": {
        "general": 0,      # ĞĞ±Ñ‰Ğ°Ñ Ñ‚ĞµĞ¼Ğ°
        "code": 1,         # ĞŸÑ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
        "system": 2,       # Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸
        "creative": 3,     # Ğ¢Ğ²Ğ¾Ñ€Ñ‡ĞµÑÑ‚Ğ²Ğ¾
        "analysis": 4,     # ĞĞ½Ğ°Ğ»Ğ¸Ğ·
    },
    "format": {
        "text": 0,         # ĞĞ±Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚
        "list": 1,         # Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº
        "steps": 2,        # ĞŸĞ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ğ¾
        "brief": 3,        # ĞšÑ€Ğ°Ñ‚ĞºĞ¾
        "detailed": 4,     # ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾
    },
}

# Ğ¡ĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ²ÑĞµĞ³Ğ¾ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… condition Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹
TOTAL_CONDITION_VALUES = sum(len(v) for v in CONDITIONS.values())

# ĞœĞ°Ñ€ĞºĞµÑ€Ñ‹ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾-Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ğ¹ Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ°
STYLE_MARKERS = {
    "formal": ["Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸", "Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸", "Ñ€Ğ°ÑÑĞºĞ°Ğ¶Ğ¸ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾", "Ğ¾Ğ¿Ğ¸ÑˆĞ¸"],
    "casual": ["Ğ½Ñƒ", "Ğ¿Ñ€Ğ¸ĞºĞ¸Ğ½ÑŒ", "ĞºĞ¾Ñ€Ğ¾Ñ‡Ğµ", "Ñ‡Ñ‘", "ĞºĞ°Ğº Ğ±Ñ‹"],
    "technical": ["Ñ€ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞ¹", "Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼", "Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ", "ĞºĞ»Ğ°ÑÑ", "api", "ĞºĞ¾Ğ´"],
    "friendly": ["Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚", "Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ¸", "Ğ¿Ğ¾Ğ´ÑĞºĞ°Ğ¶Ğ¸", "Ğ±ÑƒĞ´ÑŒ Ğ´Ğ¾Ğ±Ñ€Ğ°"],
}

MOOD_MARKERS = {
    "happy": ["Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾", "Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²Ğ¾", "ĞºÑ€ÑƒÑ‚Ğ¾", "ÑÑƒĞ¿ĞµÑ€", "ÑƒÑ€Ğ°"],
    "empathetic": ["Ğ³Ñ€ÑƒÑÑ‚Ğ½Ğ¾", "Ğ¿Ğ»Ğ¾Ñ…Ğ¾", "ÑƒÑÑ‚Ğ°Ğ»", "Ñ‚ÑĞ¶ĞµĞ»Ğ¾", "Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°"],
    "enthusiastic": ["Ğ´Ğ°Ğ²Ğ°Ğ¹", "ĞºĞ»Ğ°ÑÑĞ½Ğ¾", "wow", "Ğ¾Ğ±Ğ¾Ğ¶Ğ°Ñ", "Ñ…Ğ¾Ñ‡Ñƒ"],
}

TOPIC_MARKERS = {
    "code": ["ĞºĞ¾Ğ´", "python", "Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ", "ĞºĞ»Ğ°ÑÑ", "Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼", "ÑĞºÑ€Ğ¸Ğ¿Ñ‚",
             "Ğ±Ğ°Ğ³", "Ğ¾ÑˆĞ¸Ğ±ĞºĞ°", "Ñ„Ğ°Ğ¹Ğ»", "git", "api"],
    "system": ["Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸", "ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸", "Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹", "Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ°Ğ»", "ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°",
               "ÑĞµÑ€Ğ²ĞµÑ€", "docker", "Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ"],
    "creative": ["Ğ½Ğ°Ğ¿Ğ¸ÑˆĞ¸ ÑÑ‚Ğ¸Ñ…", "Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ", "ÑĞºĞ°Ğ·ĞºĞ°", "Ğ¿Ñ€Ğ¸Ğ´ÑƒĞ¼Ğ°Ğ¹", "Ñ„Ğ°Ğ½Ñ‚Ğ°Ğ·Ğ¸Ñ"],
    "analysis": ["Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹", "ÑÑ€Ğ°Ğ²Ğ½Ğ¸", "ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°", "Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ", "Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚"],
}

FORMAT_MARKERS = {
    "list": ["ÑĞ¿Ğ¸ÑĞ¾Ğº", "Ğ¿ĞµÑ€ĞµÑ‡Ğ¸ÑĞ»Ğ¸", "Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ñ‹", "Ğ¿ÑƒĞ½ĞºÑ‚Ñ‹"],
    "steps": ["Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ğ¾", "Ğ¿Ğ¾ ÑˆĞ°Ğ³Ğ°Ğ¼", "Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ñ", "ĞºĞ°Ğº ÑĞ´ĞµĞ»Ğ°Ñ‚ÑŒ"],
    "brief": ["ĞºÑ€Ğ°Ñ‚ĞºĞ¾", "ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¾", "Ğ² Ğ´Ğ²ÑƒÑ… ÑĞ»Ğ¾Ğ²Ğ°Ñ…", "ÑÑƒÑ‚ÑŒ"],
    "detailed": ["Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾", "Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾", "Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ", "Ñ€Ğ°Ğ·Ğ²Ñ‘Ñ€Ğ½ÑƒÑ‚Ğ¾"],
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#               CONDITION ENCODER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


@dataclass
class GenerationConditions:
    """Ğ£ÑĞ»Ğ¾Ğ²Ğ¸Ñ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸"""
    style: str = "friendly"
    mood: str = "neutral"
    topic: str = "general"
    format: str = "text"

    def to_dict(self) -> Dict[str, str]:
        return {
            "style": self.style,
            "mood": self.mood,
            "topic": self.topic,
            "format": self.format,
        }

    def __repr__(self) -> str:
        return f"[STYLE:{self.style}] [MOOD:{self.mood}] [TOPIC:{self.topic}] [FMT:{self.format}]"


class ConditionEncoder:
    """
    ĞšĞ¾Ğ´Ğ¸Ñ€ÑƒĞµÑ‚ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ² Ğ²ĞµĞºÑ‚Ğ¾Ñ€ [d_model].

    ĞšĞ°Ğ¶Ğ´Ğ¾Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ Ğ¸Ğ¼ĞµĞµÑ‚ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµĞ¼Ñ‹Ğ¹ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³.
    Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ condition_vec = ÑÑƒĞ¼Ğ¼Ğ° ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ² Ğ²ÑĞµÑ… ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ğ¹.
    """

    def __init__(self, d_model: int = 128):
        self.d_model = d_model

        # ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼Ñ‹Ğµ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¸ Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ condition value
        self._embeddings: Dict[str, Dict[str, List[float]]] = {}
        scale = math.sqrt(1.0 / d_model)

        for cond_type, values in CONDITIONS.items():
            self._embeddings[cond_type] = {}
            for value_name in values:
                self._embeddings[cond_type][value_name] = [
                    random.gauss(0, scale) for _ in range(d_model)
                ]

    def encode(self, conditions: GenerationConditions) -> List[float]:
        """
        ĞšĞ¾Ğ´Ğ¸Ñ€ÑƒĞµÑ‚ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ Ğ² Ğ¾Ğ´Ğ¸Ğ½ Ğ²ĞµĞºÑ‚Ğ¾Ñ€ [d_model].
        Ğ¡ÑƒĞ¼Ğ¼Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¸ Ğ²ÑĞµÑ… Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ğ¹.
        """
        result = [0.0] * self.d_model

        for cond_type, value in conditions.to_dict().items():
            emb = self._embeddings.get(cond_type, {}).get(value)
            if emb:
                for i in range(self.d_model):
                    result[i] += emb[i]

        # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼
        norm = math.sqrt(sum(x * x for x in result) + 1e-10)
        if norm > 0:
            scale = math.sqrt(self.d_model) / norm
            result = [x * scale for x in result]

        return result

    def get_embeddings_data(self) -> Dict:
        """Ğ¡ĞµÑ€Ğ¸Ğ°Ğ»Ğ¸Ğ·ÑƒĞµÑ‚ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¸ Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ"""
        return {
            cond_type: {
                value: emb
                for value, emb in values.items()
            }
            for cond_type, values in self._embeddings.items()
        }

    def load_embeddings_data(self, data: Dict):
        """Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¸ Ğ¸Ğ· ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ"""
        for cond_type, values in data.items():
            if cond_type in self._embeddings:
                for value, emb in values.items():
                    if value in self._embeddings[cond_type]:
                        if len(emb) == self.d_model:
                            self._embeddings[cond_type][value] = emb


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#               CONDITIONAL GENERATION ENGINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class ConditionalGeneration:
    """
    Ğ£ÑĞ»Ğ¾Ğ²Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ: Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚ĞµĞºÑÑ‚ Ñ ÑƒÑ‡Ñ‘Ñ‚Ğ¾Ğ¼ ÑÑ‚Ğ¸Ğ»Ñ, Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ñ, Ñ‚ĞµĞ¼Ñ‹.

    Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:
        cg = ConditionalGeneration(micro_transformer, bpe_tokenizer)

        # ĞĞ²Ñ‚Ğ¾-Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ğ¹
        conditions = cg.detect_conditions("ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ ĞºĞ¾Ğ´ ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸")
        # â†’ style=friendly, mood=neutral, topic=code, format=text

        # Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑĞ¼Ğ¸
        text = cg.generate(
            prompt="ĞĞ±ÑŠÑÑĞ½Ğ¸ Ñ€ĞµĞºÑƒÑ€ÑĞ¸Ñ",
            conditions=GenerationConditions(style="technical", topic="code"),
        )

        # ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ
        cg.train(
            text="Ğ ĞµĞºÑƒÑ€ÑĞ¸Ñ â€” ÑÑ‚Ğ¾ Ğ¿Ñ€Ğ¸Ñ‘Ğ¼ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ...",
            conditions=conditions,
        )
    """

    def __init__(
        self,
        micro_transformer=None,
        bpe_tokenizer=None,
        d_model: int = 128,
        db_path: Path = None,
    ):
        self._transformer = micro_transformer
        self._tokenizer = bpe_tokenizer
        self.d_model = d_model

        # Condition encoder
        self.condition_encoder = ConditionEncoder(d_model)

        # Persistence
        self._db_path = db_path or (config.config.data_dir / "conditional_gen.db")
        self._db_path.parent.mkdir(parents=True, exist_ok=True)
        self._conn = sqlite3.connect(str(self._db_path))
        self._conn.row_factory = sqlite3.Row
        self._conn.execute("PRAGMA journal_mode=WAL")
        self._create_tables()

        # Stats
        self._total_generations = 0
        self._condition_usage: Dict[str, int] = {}
        self._load_state()

        logger.info(
            f"ğŸ­ ConditionalGen: {TOTAL_CONDITION_VALUES} condition values, "
            f"{self._total_generations} generations"
        )

    def _create_tables(self):
        self._conn.execute("""
            CREATE TABLE IF NOT EXISTS cond_gen_state (
                key TEXT PRIMARY KEY,
                value TEXT NOT NULL
            )
        """)
        self._conn.execute("""
            CREATE TABLE IF NOT EXISTS cond_gen_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                prompt TEXT NOT NULL,
                conditions_json TEXT NOT NULL,
                output_len INTEGER,
                created_at REAL NOT NULL
            )
        """)
        self._conn.commit()

    def _load_state(self):
        row = self._conn.execute(
            "SELECT value FROM cond_gen_state WHERE key = 'total_generations'"
        ).fetchone()
        if row:
            self._total_generations = int(row["value"])

        row = self._conn.execute(
            "SELECT value FROM cond_gen_state WHERE key = 'condition_embeddings'"
        ).fetchone()
        if row:
            try:
                data = json.loads(row["value"])
                self.condition_encoder.load_embeddings_data(data)
            except (json.JSONDecodeError, TypeError):
                pass

        row = self._conn.execute(
            "SELECT value FROM cond_gen_state WHERE key = 'condition_usage'"
        ).fetchone()
        if row:
            try:
                self._condition_usage = json.loads(row["value"])
            except (json.JSONDecodeError, TypeError):
                pass

    def _save_state(self):
        now = time.time()
        data = [
            ("total_generations", str(self._total_generations)),
            ("condition_embeddings", json.dumps(
                self.condition_encoder.get_embeddings_data()
            )),
            ("condition_usage", json.dumps(self._condition_usage)),
        ]
        for key, val in data:
            self._conn.execute("""
                INSERT INTO cond_gen_state (key, value) VALUES (?, ?)
                ON CONFLICT(key) DO UPDATE SET value = ?
            """, (key, val, val))
        self._conn.commit()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #           ĞĞŸĞ Ğ•Ğ”Ğ•Ğ›Ğ•ĞĞ˜Ğ• Ğ£Ğ¡Ğ›ĞĞ’Ğ˜Ğ™
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def detect_conditions(
        self,
        user_input: str,
        mood: str = None,
        context: str = "",
    ) -> GenerationConditions:
        """
        ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ°.

        ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ°, Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ, Ñ‚ĞµĞ¼Ñƒ.
        """
        text = user_input.lower()
        conditions = GenerationConditions()

        # Style
        best_style = "friendly"
        best_style_score = 0
        for style, markers in STYLE_MARKERS.items():
            score = sum(1 for m in markers if m in text)
            if score > best_style_score:
                best_style_score = score
                best_style = style
        conditions.style = best_style

        # Mood
        if mood:
            conditions.mood = mood
        else:
            best_mood = "neutral"
            best_mood_score = 0
            for m, markers in MOOD_MARKERS.items():
                score = sum(1 for marker in markers if marker in text)
                if score > best_mood_score:
                    best_mood_score = score
                    best_mood = m
            conditions.mood = best_mood

        # Topic
        best_topic = "general"
        best_topic_score = 0
        for topic, markers in TOPIC_MARKERS.items():
            score = sum(1 for m in markers if m in text)
            if score > best_topic_score:
                best_topic_score = score
                best_topic = topic
        conditions.topic = best_topic

        # Format
        best_format = "text"
        best_format_score = 0
        for fmt, markers in FORMAT_MARKERS.items():
            score = sum(1 for m in markers if m in text)
            if score > best_format_score:
                best_format_score = score
                best_format = fmt
        conditions.format = best_format

        # Track usage
        key = repr(conditions)
        self._condition_usage[key] = self._condition_usage.get(key, 0) + 1

        return conditions

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #           Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ¯ Ğ¡ Ğ£Ğ¡Ğ›ĞĞ’Ğ˜Ğ¯ĞœĞ˜
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def generate(
        self,
        prompt: str,
        conditions: GenerationConditions = None,
        max_len: int = 50,
        temperature: float = 0.8,
        top_k: int = 30,
        top_p: float = 0.9,
    ) -> Optional[str]:
        """
        Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚ĞµĞºÑÑ‚ Ñ ÑƒÑ‡Ñ‘Ñ‚Ğ¾Ğ¼ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ğ¹.

        1. ĞšĞ¾Ğ´Ğ¸Ñ€ÑƒĞµÑ‚ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ Ğ² condition_vec
        2. ĞœĞ¾Ğ´Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¸ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ° condition_vec-Ğ¾Ğ¼
        3. Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‡ĞµÑ€ĞµĞ· MicroTransformer
        4. ĞŸĞ¾ÑÑ‚-Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ² ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğ¸ Ñ format

        Returns:
            Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ğ¸Ğ»Ğ¸ None
        """
        if not self._transformer or not self._tokenizer:
            return None

        if self._transformer._training_steps < 20:
            return None  # ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ°

        if conditions is None:
            conditions = self.detect_conditions(prompt)

        self._total_generations += 1

        # 1. ĞšĞ¾Ğ´Ğ¸Ñ€ÑƒĞµĞ¼ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ
        cond_vec = self.condition_encoder.encode(conditions)

        # 2. Ğ¢Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚
        prompt_ids = self._tokenizer.encode(prompt)
        if not prompt_ids or len(prompt_ids) < 1:
            return None

        # 3. ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ temperature Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ¿Ğ¾ ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑĞ¼
        temperature = self._adjust_temperature(temperature, conditions)
        max_len = self._adjust_max_len(max_len, conditions)

        # 4. Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ñ‡ĞµÑ€ĞµĞ· Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€
        # Ğ’Ğ½ĞµĞ´Ñ€ÑĞµĞ¼ condition: bias Ğ½Ğ° ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¸
        try:
            generated_ids = self._generate_with_condition(
                prompt_ids, cond_vec, max_len, temperature, top_k, top_p,
            )
        except Exception as e:
            logger.debug(f"ConditionalGen generation failed: {e}")
            return None

        if not generated_ids:
            return None

        # 5. Ğ”ĞµĞºĞ¾Ğ´Ğ¸Ñ€ÑƒĞµĞ¼
        new_ids = generated_ids[len(prompt_ids):]
        if not new_ids:
            return None

        text = self._tokenizer.decode(new_ids).strip()
        if len(text) < 3:
            return None

        # 6. ĞŸĞ¾ÑÑ‚-Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¿Ğ¾ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñƒ
        text = self._postprocess(text, conditions)

        # 7. Ğ›Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµĞ¼
        self._conn.execute("""
            INSERT INTO cond_gen_log (prompt, conditions_json, output_len, created_at)
            VALUES (?, ?, ?, ?)
        """, (prompt[:200], json.dumps(conditions.to_dict()), len(text), time.time()))

        if self._total_generations % 20 == 0:
            self._save_state()

        logger.debug(
            f"ğŸ­ Generated: {conditions} â†’ {len(text)} chars"
        )

        return text

    def _generate_with_condition(
        self,
        prompt_ids: List[int],
        cond_vec: List[float],
        max_len: int,
        temperature: float,
        top_k: int,
        top_p: float,
    ) -> List[int]:
        """
        Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ condition bias.

        Condition vector Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ÑÑ Ğº ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼Ñƒ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ñƒ ĞºĞ°Ğº bias,
        ÑĞ¼ĞµÑ‰Ğ°Ñ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ² Ğ½ÑƒĞ¶Ğ½ÑƒÑ ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ñƒ.
        """
        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ bias output
        original_bias = list(self._transformer.output_bias)

        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ condition bias Ğº output bias
        # Ğ­Ñ‚Ğ¾ ÑĞ¼ĞµÑ‰Ğ°ĞµÑ‚ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ² ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğ¸ Ñ ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑĞ¼Ğ¸
        cond_projection = self._project_condition_to_vocab(cond_vec)
        for i in range(min(len(self._transformer.output_bias), len(cond_projection))):
            self._transformer.output_bias[i] += cond_projection[i] * 0.1

        try:
            generated = self._transformer.generate(
                prompt_ids,
                max_len=max_len,
                temperature=temperature,
                top_k=top_k,
                top_p=top_p,
            )
        finally:
            # Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ bias
            self._transformer.output_bias = original_bias

        return generated

    def _project_condition_to_vocab(self, cond_vec: List[float]) -> List[float]:
        """
        ĞŸÑ€Ğ¾ĞµÑ†Ğ¸Ñ€ÑƒĞµÑ‚ condition vector [d_model] â†’ [vocab_size].
        Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ embedding weight ĞºĞ°Ğº Ğ¿Ñ€Ğ¾ĞµĞºÑ†Ğ¸Ñ (tied).
        """
        vocab_size = self._transformer.vocab_size
        d_model = len(cond_vec)

        # cond_vec @ embedding.T â†’ [vocab_size]
        result = [0.0] * vocab_size
        for token_id in range(min(vocab_size, len(self._transformer.embedding.weight))):
            emb = self._transformer.embedding.weight[token_id]
            result[token_id] = sum(
                cond_vec[j] * emb[j]
                for j in range(min(d_model, len(emb)))
            )

        return result

    def _adjust_temperature(
        self,
        base_temp: float,
        conditions: GenerationConditions,
    ) -> float:
        """ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ temperature Ğ¿Ğ¾Ğ´ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ"""
        temp = base_temp

        # Formal â†’ Ğ½Ğ¸Ğ¶Ğµ temperature (Ñ‚Ğ¾Ñ‡Ğ½ĞµĞµ)
        if conditions.style == "formal":
            temp *= 0.7
        elif conditions.style == "casual":
            temp *= 1.2
        elif conditions.style == "technical":
            temp *= 0.6

        # Brief â†’ Ğ½Ğ¸Ğ¶Ğµ (Ñ‚Ğ¾Ñ‡Ğ½ĞµĞµ)
        if conditions.format == "brief":
            temp *= 0.8
        elif conditions.format == "detailed":
            temp *= 1.1

        # Enthusiastic â†’ Ğ²Ñ‹ÑˆĞµ (Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ½ĞµĞµ)
        if conditions.mood == "enthusiastic":
            temp *= 1.15

        return max(0.1, min(1.5, temp))

    def _adjust_max_len(
        self,
        base_len: int,
        conditions: GenerationConditions,
    ) -> int:
        """ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½ÑƒÑ Ğ´Ğ»Ğ¸Ğ½Ñƒ"""
        length = base_len

        if conditions.format == "brief":
            length = min(length, 20)
        elif conditions.format == "detailed":
            length = max(length, 80)
        elif conditions.format == "steps":
            length = max(length, 60)

        return length

    def _postprocess(self, text: str, conditions: GenerationConditions) -> str:
        """ĞŸĞ¾ÑÑ‚-Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ñ‚ĞµĞºÑÑ‚Ğ° Ğ¿Ğ¾ ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑĞ¼ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ°"""
        # Ğ”Ğ»Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ° "list" â€” Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¼Ğ°Ñ€ĞºĞµÑ€Ñ‹ ĞµÑĞ»Ğ¸ Ğ½ĞµÑ‚
        if conditions.format == "list" and not re.search(r'^\s*[-â€¢\d]', text):
            sentences = [s.strip() for s in re.split(r'[.!?]\s+', text) if s.strip()]
            if len(sentences) > 1:
                text = "\n".join(f"â€¢ {s}" for s in sentences)

        # Ğ”Ğ»Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ° "steps" â€” Ğ½ÑƒĞ¼ĞµÑ€ÑƒĞµĞ¼
        if conditions.format == "steps" and not re.search(r'^\s*\d', text):
            sentences = [s.strip() for s in re.split(r'[.!?]\s+', text) if s.strip()]
            if len(sentences) > 1:
                text = "\n".join(f"{i+1}. {s}" for i, s in enumerate(sentences))

        # Ğ”Ğ»Ñ brief â€” Ğ¾Ğ±Ñ€ĞµĞ·Ğ°ĞµĞ¼
        if conditions.format == "brief":
            sentences = re.split(r'[.!?]\s+', text)
            if len(sentences) > 2:
                text = ". ".join(sentences[:2]) + "."

        return text

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #           ĞĞ‘Ğ£Ğ§Ğ•ĞĞ˜Ğ•
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def train(
        self,
        text: str,
        conditions: GenerationConditions,
    ):
        """
        ĞĞ±ÑƒÑ‡Ğ°ĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑĞ¼Ğ¸.

        Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ condition bias Ğ¿Ñ€Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸, Ñ‚Ğ°Ğº Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ°ÑÑĞ¾Ñ†Ğ¸Ğ¸Ñ€ÑƒĞµÑ‚
        ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½Ğ½Ñ‹Ğ¼Ğ¸ ÑÑ‚Ğ¸Ğ»ÑĞ¼Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ°.
        """
        if not self._transformer or not self._tokenizer:
            return

        token_ids = self._tokenizer.encode(text)
        if len(token_ids) < 3:
            return

        # ĞšĞ¾Ğ´Ğ¸Ñ€ÑƒĞµĞ¼ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ
        cond_vec = self.condition_encoder.encode(conditions)

        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ condition bias Ğ½Ğ° Ğ²Ñ€ĞµĞ¼Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
        original_bias = list(self._transformer.output_bias)
        cond_projection = self._project_condition_to_vocab(cond_vec)

        for i in range(min(len(self._transformer.output_bias), len(cond_projection))):
            self._transformer.output_bias[i] += cond_projection[i] * 0.05

        try:
            self._transformer.train_step(token_ids)
        finally:
            self._transformer.output_bias = original_bias

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #           Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def get_stats(self) -> Dict:
        # Top conditions
        top_conditions = sorted(
            self._condition_usage.items(),
            key=lambda x: x[1],
            reverse=True,
        )[:5]

        return {
            "total_generations": self._total_generations,
            "condition_types": len(CONDITIONS),
            "condition_values": TOTAL_CONDITION_VALUES,
            "top_conditions": top_conditions,
        }

    def close(self):
        self._save_state()
        self._conn.close()
