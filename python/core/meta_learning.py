"""
–ö—Ä–∏—Å—Ç–∏–Ω–∞ 7.3 ‚Äî Meta-Learning (–ú–µ—Ç–∞-–æ–±—É—á–µ–Ω–∏–µ / Learning-to-Learn)

–ó–ê–ß–ï–ú:
  –ö—Ä–∏—Å—Ç–∏–Ω–∞ –æ–±—É—á–∞–µ—Ç –º–Ω–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ:
    - MicroTransformer (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞)
    - MoE (–º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤)
    - KnowledgeDistillation (–¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏—è LLM)
    - ConditionalGen (—É—Å–ª–æ–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è)
    - ResponseGenerator (–ø—Ä–∞–≤–∏–ª–∞ ‚Üí –æ—Ç–≤–µ—Ç—ã)
    - IntentRouter (–º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤)
    - Word2Vec (—ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–ª–æ–≤)

  –ù–æ –ö–ê–ö –æ–±—É—á–∞—Ç—å –∫–∞–∂–¥—ã–π –∏–∑ –Ω–∏—Ö –õ–£–ß–®–ï?
    - –ö–æ–º—É —Å–µ–π—á–∞—Å –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö?
    - –ß–µ–π learning rate —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏–π/–Ω–∏–∑–∫–∏–π?
    - –ö—Ç–æ –∑–∞—Å—Ç—Ä—è–ª –Ω–∞ –ø–ª–∞—Ç–æ?
    - –ö–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∫–∞–∂–¥–æ–º—É –ø–æ–ª–µ–∑–Ω—ã?

  META-LEARNING –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ —ç—Ç–∏ –≤–æ–ø—Ä–æ—Å—ã.
  –≠—Ç–æ "–æ–±—É—á–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—é" ‚Äî —Å–∏—Å—Ç–µ–º–∞, –∫–æ—Ç–æ—Ä–∞—è –û–ü–¢–ò–ú–ò–ó–ò–†–£–ï–¢ –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è.

–ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ MetaLearner                                         ‚îÇ
  ‚îÇ                                                     ‚îÇ
  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
  ‚îÇ  ‚îÇ LearnerProfile‚îÇ√óN ‚îÇ SchedulerStrategy         ‚îÇ  ‚îÇ
  ‚îÇ  ‚îÇ - loss_history‚îÇ    ‚îÇ - adaptive_lr             ‚îÇ  ‚îÇ
  ‚îÇ  ‚îÇ - lr          ‚îÇ    ‚îÇ - plateau_detection       ‚îÇ  ‚îÇ
  ‚îÇ  ‚îÇ - is_plateau  ‚îÇ    ‚îÇ - curriculum_ordering     ‚îÇ  ‚îÇ
  ‚îÇ  ‚îÇ - importance  ‚îÇ    ‚îÇ - resource_allocation     ‚îÇ  ‚îÇ
  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
  ‚îÇ                                                     ‚îÇ
  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
  ‚îÇ  ‚îÇ CurriculumScheduler                          ‚îÇ   ‚îÇ
  ‚îÇ  ‚îÇ  - –ü–æ—Ä—è–¥–æ–∫ –æ–±—É—á–µ–Ω–∏—è: –æ—Ç –ø—Ä–æ—Å—Ç–æ–≥–æ –∫ —Å–ª–æ–∂–Ω–æ–º—É  ‚îÇ   ‚îÇ
  ‚îÇ  ‚îÇ  - –§–æ–∫—É—Å: –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö —Ç—É–¥–∞, –≥–¥–µ –Ω—É–∂–Ω–µ–µ     ‚îÇ   ‚îÇ
  ‚îÇ  ‚îÇ  - –ë–∞–ª–∞–Ω—Å: exploration vs exploitation       ‚îÇ   ‚îÇ
  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
  ‚îÇ                                                     ‚îÇ
  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
  ‚îÇ  ‚îÇ PerformanceTracker                           ‚îÇ   ‚îÇ
  ‚îÇ  ‚îÇ  - –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞                ‚îÇ   ‚îÇ
  ‚îÇ  ‚îÇ  - –¢—Ä–µ–Ω–¥—ã (—É–ª—É—á—à–∞–µ—Ç—Å—è/—Å—Ç–∞–≥–Ω–∏—Ä—É–µ—Ç/–¥–µ–≥—Ä–∞–¥–∏—Ä—É–µ—Ç)‚îÇ   ‚îÇ
  ‚îÇ  ‚îÇ  - –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏             ‚îÇ   ‚îÇ
  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
"""

import json
import math
import random
import sqlite3
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from enum import Enum

from utils.logging import get_logger
import config

logger = get_logger("meta_learning")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#               LEARNER PROFILE
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


class Trend(Enum):
    IMPROVING = "improving"
    PLATEAU = "plateau"
    DEGRADING = "degrading"
    UNKNOWN = "unknown"


@dataclass
class LearnerProfile:
    """
    –ü—Ä–æ—Ñ–∏–ª—å –æ–¥–Ω–æ–≥–æ –æ–±—É—á–∞–µ–º–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞.
    Meta-Learning –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –∫–∞–∂–¥—ã–π.
    """
    name: str
    # Learning rate
    base_lr: float = 3e-4
    current_lr: float = 3e-4
    lr_min: float = 1e-5
    lr_max: float = 1e-2
    # Loss tracking
    loss_history: List[float] = field(default_factory=list)
    loss_window: int = 20       # –°–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ –¥–ª—è —Ç—Ä–µ–Ω–¥–∞
    # Stats
    total_steps: int = 0
    total_improvements: int = 0
    plateau_count: int = 0      # –°–∫–æ–ª—å–∫–æ —Ä–∞–∑ –±—ã–ª plateau
    # Importance (meta-learned)
    importance: float = 1.0     # –ù–∞—Å–∫–æ–ª—å–∫–æ —ç—Ç–æ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –≤–∞–∂–µ–Ω
    # Training probability
    train_prob: float = 1.0     # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –¥–∞–Ω–Ω–æ–º —à–∞–≥–µ
    # Trend
    trend: Trend = Trend.UNKNOWN

    def record_loss(self, loss: float):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç loss –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç —Ç—Ä–µ–Ω–¥"""
        self.loss_history.append(loss)
        if len(self.loss_history) > 200:
            self.loss_history = self.loss_history[-200:]
        self.total_steps += 1
        self._update_trend()

    def _update_trend(self):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç—Ä–µ–Ω–¥ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º loss-–∑–Ω–∞—á–µ–Ω–∏—è–º"""
        if len(self.loss_history) < self.loss_window:
            self.trend = Trend.UNKNOWN
            return

        recent = self.loss_history[-self.loss_window:]
        older = self.loss_history[-self.loss_window * 2:-self.loss_window] \
            if len(self.loss_history) >= self.loss_window * 2 \
            else self.loss_history[:self.loss_window]

        avg_recent = sum(recent) / len(recent)
        avg_older = sum(older) / len(older)

        ratio = avg_recent / (avg_older + 1e-10)

        if ratio < 0.95:
            self.trend = Trend.IMPROVING
            self.total_improvements += 1
        elif ratio > 1.05:
            self.trend = Trend.DEGRADING
        else:
            self.trend = Trend.PLATEAU
            self.plateau_count += 1

    def avg_recent_loss(self) -> float:
        if not self.loss_history:
            return float('inf')
        window = min(10, len(self.loss_history))
        return sum(self.loss_history[-window:]) / window

    def to_dict(self) -> Dict:
        return {
            "name": self.name,
            "current_lr": self.current_lr,
            "total_steps": self.total_steps,
            "avg_loss": round(self.avg_recent_loss(), 6),
            "trend": self.trend.value,
            "importance": round(self.importance, 3),
            "train_prob": round(self.train_prob, 3),
            "plateau_count": self.plateau_count,
        }


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#               ADAPTIVE LR SCHEDULER
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


class AdaptiveLRScheduler:
    """
    –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π learning rate –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞.

    –°—Ç—Ä–∞—Ç–µ–≥–∏–∏:
    - Reduce on plateau: lr *= 0.5 –ø—Ä–∏ —Å—Ç–∞–≥–Ω–∞—Ü–∏–∏
    - Warmup: –ª–∏–Ω–µ–π–Ω—ã–π —Ä–æ—Å—Ç lr –Ω–∞ –ø–µ—Ä–≤—ã—Ö N —à–∞–≥–∞—Ö
    - Cosine annealing: –ø–ª–∞–≤–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ
    - Importance-weighted: –±–æ–ª—å—à–µ lr –≤–∞–∂–Ω—ã–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º
    """

    def __init__(self, warmup_steps: int = 50):
        self.warmup_steps = warmup_steps

    def step(self, profile: LearnerProfile) -> float:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç –Ω–æ–≤—ã–π learning rate –¥–ª—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞.

        Returns:
            –û–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π lr
        """
        lr = profile.current_lr

        # 1. Warmup (–ø–µ—Ä–≤—ã–µ N —à–∞–≥–æ–≤)
        if profile.total_steps < self.warmup_steps:
            warmup_factor = (profile.total_steps + 1) / self.warmup_steps
            lr = profile.base_lr * warmup_factor
            profile.current_lr = lr
            return lr

        # 2. Plateau detection ‚Üí reduce
        if profile.trend == Trend.PLATEAU:
            lr *= 0.8  # –ú—è–≥–∫–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ
            if profile.plateau_count > 3:
                lr *= 0.5  # –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö plateau

        # 3. Degradation ‚Üí –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ
        elif profile.trend == Trend.DEGRADING:
            lr *= 0.5

        # 4. Improving ‚Üí –º–æ–∂–Ω–æ –Ω–µ–º–Ω–æ–≥–æ —É–≤–µ–ª–∏—á–∏—Ç—å
        elif profile.trend == Trend.IMPROVING:
            lr *= 1.05

        # 5. Cosine component (–º—è–≥–∫–æ–µ –∑–∞—Ç—É—Ö–∞–Ω–∏–µ —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º)
        decay_steps = max(1, profile.total_steps - self.warmup_steps)
        cosine_factor = 0.5 * (1 + math.cos(math.pi * min(decay_steps / 5000, 1.0)))
        cosine_lr = profile.lr_min + (profile.base_lr - profile.lr_min) * cosine_factor

        # Blend: 70% adaptive + 30% cosine
        lr = 0.7 * lr + 0.3 * cosine_lr

        # Clamp
        lr = max(profile.lr_min, min(profile.lr_max, lr))

        profile.current_lr = lr
        return lr


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#               CURRICULUM SCHEDULER
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


class CurriculumScheduler:
    """
    Curriculum Learning: –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–æ—Ä—è–¥–æ–∫ –∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –æ–±—É—á–µ–Ω–∏—è.

    –ü—Ä–∏–Ω—Ü–∏–ø—ã:
    1. –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å –±–û–ª—å—à–∏–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–º —É–ª—É—á—à–µ–Ω–∏—è ‚Üí –±–æ–ª—å—à–µ –æ–±—É—á–µ–Ω–∏—è
    2. –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–∞ plateau ‚Üí –º–µ–Ω—å—à–µ –æ–±—É—á–µ–Ω–∏—è (—ç–∫–æ–Ω–æ–º–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤)
    3. Exploration: –∏–Ω–æ–≥–¥–∞ –æ–±—É—á–∞–µ–º "–∑–∞–±—ã—Ç—ã–µ" –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    4. Dependency-aware: base components first
    """

    def __init__(self, exploration_rate: float = 0.1):
        self.exploration_rate = exploration_rate
        self._step = 0

    def compute_train_probabilities(
        self,
        profiles: Dict[str, LearnerProfile],
    ) -> Dict[str, float]:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞.

        Returns:
            {component_name: probability}
        """
        self._step += 1
        probs = {}

        for name, profile in profiles.items():
            prob = self._compute_single_prob(profile)
            probs[name] = prob
            profile.train_prob = prob

        return probs

    def _compute_single_prob(self, profile: LearnerProfile) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –æ–¥–Ω–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞"""
        base_prob = 1.0

        # Trend-based adjustment
        if profile.trend == Trend.IMPROVING:
            base_prob = 1.0  # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º ‚Äî —Ä–∞–±–æ—Ç–∞–µ—Ç!
        elif profile.trend == Trend.PLATEAU:
            base_prob = 0.3  # –°–Ω–∏–∂–∞–µ–º ‚Äî –º–∞–ª–æ –ø–æ–ª—å–∑—ã
        elif profile.trend == Trend.DEGRADING:
            base_prob = 0.5  # –°–Ω–∏–∂–∞–µ–º, –Ω–æ –Ω–µ —É–±–∏—Ä–∞–µ–º (–º–æ–∂–µ—Ç –∏—Å–ø—Ä–∞–≤–∏—Ç—å—Å—è)
        else:
            base_prob = 0.8  # Unknown ‚Äî –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ –æ–±—É—á–∞–µ–º

        # Importance weighting
        base_prob *= profile.importance

        # Exploration: —Å–ª—É—á–∞–π–Ω—ã–π —à–∞–Ω—Å –æ–±—É—á–∏—Ç—å –¥–∞–∂–µ "–Ω–µ–≤–∞–∂–Ω—ã–π" –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
        if random.random() < self.exploration_rate:
            base_prob = max(base_prob, 0.5)

        return min(1.0, max(0.05, base_prob))

    def should_train(self, profile: LearnerProfile) -> bool:
        """–†–µ—à–∞–µ—Ç, –æ–±—É—á–∞—Ç—å –ª–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –Ω–∞ —ç—Ç–æ–º —à–∞–≥–µ"""
        return random.random() < profile.train_prob


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#               PERFORMANCE TRACKER
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


class PerformanceTracker:
    """
    –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –æ–±—â—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã –∏ –≤–∫–ª–∞–¥ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤.
    """

    def __init__(self):
        self._response_quality: List[float] = []  # 0-1
        self._tier_distribution: Dict[str, int] = {}
        self._component_contributions: Dict[str, List[float]] = {}

    def record_response(
        self,
        quality: float,
        tier: str,
        contributing_components: List[str] = None,
    ):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–∞ –∏ —É—á–∞—Å—Ç–≤—É—é—â–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã"""
        self._response_quality.append(quality)
        if len(self._response_quality) > 500:
            self._response_quality = self._response_quality[-500:]

        self._tier_distribution[tier] = self._tier_distribution.get(tier, 0) + 1

        if contributing_components:
            for comp in contributing_components:
                if comp not in self._component_contributions:
                    self._component_contributions[comp] = []
                self._component_contributions[comp].append(quality)
                if len(self._component_contributions[comp]) > 200:
                    self._component_contributions[comp] = \
                        self._component_contributions[comp][-200:]

    def compute_importance(self, profiles: Dict[str, LearnerProfile]):
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç importance –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ –ø–æ –µ–≥–æ –≤–∫–ª–∞–¥—É –≤ –∫–∞—á–µ—Å—Ç–≤–æ.
        """
        for name, profile in profiles.items():
            contributions = self._component_contributions.get(name, [])
            if len(contributions) >= 5:
                avg_quality = sum(contributions) / len(contributions)
                # Importance –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–∞ —Å—Ä–µ–¥–Ω–µ–º—É –∫–∞—á–µ—Å—Ç–≤—É –∏ —á–∞—Å—Ç–æ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                frequency = len(contributions) / max(1, len(self._response_quality))
                profile.importance = 0.7 * avg_quality + 0.3 * frequency
            else:
                profile.importance = 0.5  # Default –¥–ª—è –Ω–æ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

    def avg_quality(self, window: int = 50) -> float:
        if not self._response_quality:
            return 0.0
        recent = self._response_quality[-window:]
        return sum(recent) / len(recent)

    def quality_trend(self) -> Trend:
        """–¢—Ä–µ–Ω–¥ –æ–±—â–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞"""
        if len(self._response_quality) < 20:
            return Trend.UNKNOWN

        recent = self._response_quality[-10:]
        older = self._response_quality[-20:-10]

        avg_r = sum(recent) / len(recent)
        avg_o = sum(older) / len(older)

        if avg_r > avg_o * 1.05:
            return Trend.IMPROVING
        elif avg_r < avg_o * 0.95:
            return Trend.DEGRADING
        return Trend.PLATEAU

    def get_stats(self) -> Dict:
        return {
            "avg_quality": round(self.avg_quality(), 4),
            "quality_trend": self.quality_trend().value,
            "total_responses": len(self._response_quality),
            "tier_distribution": dict(self._tier_distribution),
        }


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#               META-LEARNER (–≥–ª–∞–≤–Ω—ã–π –º–æ–¥—É–ª—å)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


# –í—Å–µ —É–ø—Ä–∞–≤–ª—è–µ–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
MANAGED_COMPONENTS = [
    "micro_transformer",
    "moe",
    "conditional_gen",
    "knowledge_distillation",
    "response_generator",
    "intent_router",
    "word2vec",
]


class MetaLearner:
    """
    Meta-Learning: —Å–∏—Å—Ç–µ–º–∞, –∫–æ—Ç–æ—Ä–∞—è —É—á–∏—Ç—Å—è –£–ß–ò–¢–¨ –¥—Ä—É–≥–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã.

    –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
        meta = MetaLearner()

        # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
        meta.register("micro_transformer", base_lr=3e-4)

        # –ü–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º ‚Äî –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        should = meta.should_train("micro_transformer")
        lr = meta.get_lr("micro_transformer")

        # –ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è ‚Äî —Å–æ–æ–±—â–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        meta.report_loss("micro_transformer", loss=0.42)

        # –ü–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞ ‚Äî —Å–æ–æ–±—â–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ
        meta.report_response(quality=0.8, tier="tier1",
                            components=["micro_transformer", "moe"])

        # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ ‚Äî –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å
        meta.optimize_step()
    """

    def __init__(self, db_path: Path = None):
        # Profiles
        self.profiles: Dict[str, LearnerProfile] = {}

        # Sub-systems
        self.lr_scheduler = AdaptiveLRScheduler()
        self.curriculum = CurriculumScheduler()
        self.performance = PerformanceTracker()

        # Persistence
        self._db_path = db_path or (config.config.data_dir / "meta_learning.db")
        self._db_path.parent.mkdir(parents=True, exist_ok=True)
        self._conn = sqlite3.connect(str(self._db_path))
        self._conn.execute("PRAGMA journal_mode=WAL")
        self._create_tables()

        # Global stats
        self._total_meta_steps = 0
        self._load_state()

        # Register default components
        for comp in MANAGED_COMPONENTS:
            if comp not in self.profiles:
                self.register(comp)

        logger.info(
            f"üß¨ MetaLearner: {len(self.profiles)} components, "
            f"{self._total_meta_steps} meta-steps"
        )

    def _create_tables(self):
        self._conn.execute("""
            CREATE TABLE IF NOT EXISTS meta_state (
                key TEXT PRIMARY KEY,
                value TEXT NOT NULL
            )
        """)
        self._conn.execute("""
            CREATE TABLE IF NOT EXISTS meta_events (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                event_type TEXT NOT NULL,
                component TEXT,
                data TEXT,
                created_at REAL NOT NULL
            )
        """)
        self._conn.commit()

    def _load_state(self):
        row = self._conn.execute(
            "SELECT value FROM meta_state WHERE key = 'state'"
        ).fetchone()
        if row:
            try:
                data = json.loads(row[0])
                self._total_meta_steps = data.get("total_meta_steps", 0)
                for name, pdata in data.get("profiles", {}).items():
                    profile = LearnerProfile(name=name)
                    profile.base_lr = pdata.get("base_lr", 3e-4)
                    profile.current_lr = pdata.get("current_lr", 3e-4)
                    profile.total_steps = pdata.get("total_steps", 0)
                    profile.total_improvements = pdata.get("total_improvements", 0)
                    profile.plateau_count = pdata.get("plateau_count", 0)
                    profile.importance = pdata.get("importance", 1.0)
                    profile.train_prob = pdata.get("train_prob", 1.0)
                    profile.loss_history = pdata.get("loss_history", [])[-100:]
                    trend_str = pdata.get("trend", "unknown")
                    profile.trend = Trend(trend_str)
                    self.profiles[name] = profile
            except (json.JSONDecodeError, TypeError):
                pass

    def _save_state(self):
        data = {
            "total_meta_steps": self._total_meta_steps,
            "profiles": {
                name: {
                    "base_lr": p.base_lr,
                    "current_lr": p.current_lr,
                    "total_steps": p.total_steps,
                    "total_improvements": p.total_improvements,
                    "plateau_count": p.plateau_count,
                    "importance": p.importance,
                    "train_prob": p.train_prob,
                    "loss_history": p.loss_history[-100:],
                    "trend": p.trend.value,
                }
                for name, p in self.profiles.items()
            },
        }
        json_str = json.dumps(data)
        self._conn.execute("""
            INSERT INTO meta_state (key, value) VALUES ('state', ?)
            ON CONFLICT(key) DO UPDATE SET value = ?
        """, (json_str, json_str))
        self._conn.commit()

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    #           COMPONENT MANAGEMENT
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def register(
        self,
        name: str,
        base_lr: float = 3e-4,
        importance: float = 1.0,
    ):
        """–†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è –º–µ—Ç–∞-–æ–±—É—á–µ–Ω–∏—è"""
        if name not in self.profiles:
            self.profiles[name] = LearnerProfile(
                name=name,
                base_lr=base_lr,
                current_lr=base_lr,
                importance=importance,
            )

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    #           TRAINING DECISIONS
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def should_train(self, component: str) -> bool:
        """–†–µ—à–∞–µ—Ç, –æ–±—É—á–∞—Ç—å –ª–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç —Å–µ–π—á–∞—Å"""
        profile = self.profiles.get(component)
        if not profile:
            return True
        return self.curriculum.should_train(profile)

    def get_lr(self, component: str) -> float:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–∏–π learning rate –¥–ª—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞"""
        profile = self.profiles.get(component)
        if not profile:
            return 3e-4
        return profile.current_lr

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    #           REPORTING
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def report_loss(self, component: str, loss: float):
        """–°–æ–æ–±—â–∞–µ—Ç loss –ø–æ—Å–ª–µ —à–∞–≥–∞ –æ–±—É—á–µ–Ω–∏—è"""
        profile = self.profiles.get(component)
        if not profile:
            self.register(component)
            profile = self.profiles[component]

        profile.record_loss(loss)

        # Update LR
        self.lr_scheduler.step(profile)

    def report_response(
        self,
        quality: float,
        tier: str,
        components: List[str] = None,
    ):
        """–°–æ–æ–±—â–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–∞ –∏ —É—á–∞—Å—Ç–≤—É—é—â–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã"""
        self.performance.record_response(
            quality=quality,
            tier=tier,
            contributing_components=components,
        )

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    #           META-OPTIMIZATION STEP
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def optimize_step(self):
        """
        –û–¥–∏–Ω —à–∞–≥ –º–µ—Ç–∞-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ (–∫–∞–∂–¥—ã–µ N –∑–∞–ø—Ä–æ—Å–æ–≤).

        –û–±–Ω–æ–≤–ª—è–µ—Ç:
        1. Training probabilities –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
        2. Importance scores
        3. Learning rates
        """
        self._total_meta_steps += 1

        # 1. Update importance from performance
        self.performance.compute_importance(self.profiles)

        # 2. Update training probabilities
        self.curriculum.compute_train_probabilities(self.profiles)

        # 3. Update LRs
        for profile in self.profiles.values():
            self.lr_scheduler.step(profile)

        # 4. Log meta-state
        if self._total_meta_steps % 10 == 0:
            self._log_meta_state()

        # 5. Save
        if self._total_meta_steps % 5 == 0:
            self._save_state()

    def _log_meta_state(self):
        """–õ–æ–≥–∏—Ä—É–µ—Ç —Ç–µ–∫—É—â–µ–µ –º–µ—Ç–∞-—Å–æ—Å—Ç–æ—è–Ω–∏–µ"""
        improving = sum(1 for p in self.profiles.values() if p.trend == Trend.IMPROVING)
        plateau = sum(1 for p in self.profiles.values() if p.trend == Trend.PLATEAU)
        degrading = sum(1 for p in self.profiles.values() if p.trend == Trend.DEGRADING)

        avg_q = self.performance.avg_quality()

        logger.info(
            f"üß¨ Meta step #{self._total_meta_steps}: "
            f"quality={avg_q:.3f}, "
            f"trends: {improving}‚Üë {plateau}‚Üí {degrading}‚Üì"
        )

        # Log individual components with issues
        for name, profile in self.profiles.items():
            if profile.trend == Trend.DEGRADING:
                logger.warning(
                    f"üß¨ {name}: DEGRADING (lr={profile.current_lr:.6f}, "
                    f"loss={profile.avg_recent_loss():.4f})"
                )
            elif profile.trend == Trend.PLATEAU and profile.plateau_count > 2:
                logger.info(
                    f"üß¨ {name}: persistent plateau "
                    f"(count={profile.plateau_count}, lr={profile.current_lr:.6f})"
                )

        # Record event
        self._conn.execute("""
            INSERT INTO meta_events (event_type, data, created_at)
            VALUES ('meta_step', ?, ?)
        """, (json.dumps({
            "step": self._total_meta_steps,
            "avg_quality": avg_q,
            "improving": improving,
            "plateau": plateau,
            "degrading": degrading,
        }), time.time()))

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    #           RECOMMENDATIONS
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def get_recommendations(self) -> List[str]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–±—É—á–µ–Ω–∏—é.
        """
        recs = []

        for name, profile in self.profiles.items():
            if profile.trend == Trend.DEGRADING:
                recs.append(
                    f"{name}: –¥–µ–≥—Ä–∞–¥–∏—Ä—É–µ—Ç ‚Äî —Å–Ω–∏–∑–∏—Ç—å lr –∏–ª–∏ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ"
                )
            elif profile.trend == Trend.PLATEAU and profile.plateau_count > 5:
                recs.append(
                    f"{name}: –¥–ª–∏—Ç–µ–ª—å–Ω—ã–π plateau ‚Äî –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å lr restart"
                )

        # Overall quality
        q_trend = self.performance.quality_trend()
        if q_trend == Trend.DEGRADING:
            recs.append("–û–±—â–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Å–Ω–∏–∂–∞–µ—Ç—Å—è ‚Äî –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ–±—É—á–µ–Ω–∏—è")
        elif q_trend == Trend.IMPROVING:
            recs.append("–û–±—â–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Ä–∞—Å—Ç—ë—Ç ‚Äî –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é")

        # Resource allocation
        high_importance = sorted(
            self.profiles.values(),
            key=lambda p: p.importance,
            reverse=True,
        )
        if high_importance:
            top = high_importance[0]
            if top.train_prob < 0.5:
                recs.append(
                    f"{top.name}: –≤—ã—Å–æ–∫–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å, –Ω–æ –Ω–∏–∑–∫–∞—è train_prob ‚Äî "
                    f"—É–≤–µ–ª–∏—á–∏—Ç—å —Ä–µ—Å—É—Ä—Å—ã"
                )

        return recs

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    #           STATISTICS
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def get_stats(self) -> Dict:
        component_stats = {
            name: profile.to_dict()
            for name, profile in self.profiles.items()
        }

        return {
            "total_meta_steps": self._total_meta_steps,
            "components": component_stats,
            "performance": self.performance.get_stats(),
            "recommendations": self.get_recommendations(),
        }

    def close(self):
        self._save_state()
        self._conn.close()
