"""
ĞšÑ€Ğ¸ÑÑ‚Ğ¸Ğ½Ğ° 5.0 â€” Multi-Agent AI Assistant (Hybrid Rust+Python)

Ğ¢Ğ¾Ñ‡ĞºĞ° Ğ²Ñ…Ğ¾Ğ´Ğ°. Ğ’ÑĞµ CPU-Ğ¸Ğ½Ñ‚ĞµĞ½ÑĞ¸Ğ²Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ÑƒĞ»Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ Ñ‡ĞµÑ€ĞµĞ· Rust ÑĞ´Ñ€Ğ¾ (kristina_core).
Ğ•ÑĞ»Ğ¸ Rust Ğ½Ğµ ÑĞ¾Ğ±Ñ€Ğ°Ğ½ â€” Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ fallback Ğ½Ğ° Python.
"""

import asyncio
import sys
import signal
from pathlib import Path

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ĞºĞ¾Ñ€Ğ½ĞµĞ²ÑƒÑ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ
sys.path.insert(0, str(Path(__file__).parent))

import structlog
from config import config

# â”€â”€ Structured logging â”€â”€
structlog.configure(
    processors=[
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.add_log_level,
        structlog.dev.ConsoleRenderer(colors=True),
    ],
    wrapper_class=structlog.BoundLogger,
    logger_factory=structlog.PrintLoggerFactory(),
)
log = structlog.get_logger("kristina")

# â”€â”€ Rust/Python bridge â”€â”€
from bridge import (
    RUST_AVAILABLE, MemoryEngine, EmbeddingCache, EmotionAnalyzer,
    ToolCallParser, ContextCompressor, ThreadTracker,
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                    GRACEFUL SHUTDOWN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class GracefulShutdown:
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ"""

    def __init__(self):
        self.should_exit = False
        signal.signal(signal.SIGINT, self._handle)
        signal.signal(signal.SIGTERM, self._handle)

    def _handle(self, signum, frame):
        name = "SIGINT" if signum == signal.SIGINT else "SIGTERM"
        log.info("shutdown_signal", signal=name)
        self.should_exit = True


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                    Ğ˜ĞĞ˜Ğ¦Ğ˜ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def initialize_system():
    """Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²ÑĞµ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹"""

    log.info("system_init", version="6.0", rust_core=RUST_AVAILABLE)

    # â”€â”€ Health check: Ollama â”€â”€
    try:
        from ollama import AsyncClient
        client = AsyncClient()
        await client.list()
        log.info("ollama_connected")
    except Exception as e:
        log.error("ollama_unavailable", error=str(e))
        print(f"\nâŒ Ollama Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ°: {e}")
        print("   Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸ Ollama: ollama serve")
        sys.exit(1)

    # â”€â”€ Rust/Hybrid ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ â”€â”€
    memory = MemoryEngine(
        str(config.memory_dir),
        working_size=config.working_memory_size,
        max_episodic=config.max_episodic_memory,
    )
    log.info("component_ready", name="MemoryEngine", backend="rust" if RUST_AVAILABLE else "python")

    embedding_cache = EmbeddingCache(
        str(config.data_dir),
        max_size=config.embedding_cache_max_size,
    )
    log.info("component_ready", name="EmbeddingCache",
             size=embedding_cache.len(),
             backend="rust" if RUST_AVAILABLE else "python")

    emotion_analyzer = EmotionAnalyzer()

    tool_parser = ToolCallParser([])  # Ğ—Ğ°Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑÑ Ğ¿Ğ¾ÑĞ»Ğµ Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ tools

    context_compressor = ContextCompressor(compression_ratio=0.3)

    thread_tracker = ThreadTracker(timeout_secs=config.thread_timeout_seconds)

    # v6.0: ĞĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ÑƒĞ»Ğ¸ (consciousness + SIGMA)
    from core.emotions_vad import VADEmotionalEngine
    from core.metacognition import MetaCognition
    from core.self_awareness import SelfAwareness

    vad_emotions = VADEmotionalEngine()
    metacognition = MetaCognition()
    self_awareness = SelfAwareness()
    log.info("component_ready", name="VAD+MetaCog+SelfAwareness", source="consciousness+sigma")

    # â”€â”€ Python ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ (I/O-bound, Rust Ğ½Ğµ Ğ½ÑƒĞ¶ĞµĞ½) â”€â”€
    from core.identity import IdentityEngine

    identity = IdentityEngine()

    # Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ»ĞµÑ€
    from modules.system_control.controller import SystemController
    system_controller = SystemController()

    # â”€â”€ Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ â”€â”€
    # Ğ’ĞµĞ± (web_tools.py â€” Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğµ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸, Ğ±ĞµĞ· Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ²)
    from tools.web_tools import WebSearchTool, WebFetchTool, GetWeatherTool, GetCurrentTimeTool
    # Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° (Ğ±ĞµĞ· Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ² GetWeatherTool/GetCurrentTimeTool)
    from tools.system_tools import (
        SystemStatusTool, LaunchAppTool, ListProcessesTool,
    )
    from tools.file_tools import (
        SearchFilesTool, ReadFileTool, DeleteFileTool,
        ListDirectoryTool, CreateFileTool, WriteFileTool,
    )
    from tools.memory_tools import RecallMemoryTool, SearchMemoryTool

    tools = {}

    # Ğ’ĞµĞ±
    for cls in [WebSearchTool, WebFetchTool]:
        t = cls()
        tools[t.schema.name] = t.execute

    # Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ°
    for cls, needs_ctrl in [
        (SystemStatusTool, True), (LaunchAppTool, True),
        (ListProcessesTool, True),
    ]:
        t = cls(system_controller)
        tools[t.schema.name] = t.execute

    # Ğ’Ñ€ĞµĞ¼Ñ Ğ¸ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ° (Ğ¸Ğ· web_tools â€” Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğµ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸)
    for cls in [GetCurrentTimeTool, GetWeatherTool]:
        t = cls()
        tools[t.schema.name] = t.execute

    # Ğ¤Ğ°Ğ¹Ğ»Ñ‹
    for cls in [SearchFilesTool, ReadFileTool, DeleteFileTool,
                ListDirectoryTool, CreateFileTool, WriteFileTool]:
        t = cls(system_controller) if cls == SearchFilesTool else cls()
        tools[t.schema.name] = t.execute

    # ĞŸĞ°Ğ¼ÑÑ‚ÑŒ
    from modules.rag.vector_store import VectorMemory
    vector_memory = VectorMemory()

    for cls in [RecallMemoryTool, SearchMemoryTool]:
        t = cls(memory) if cls == RecallMemoryTool else cls(vector_memory)
        tools[t.schema.name] = t.execute

    # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¿Ğ°Ñ€ÑĞµÑ€ Ñ Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¼Ğ¸ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸
    tool_parser.set_known_tools(list(tools.keys()))

    log.info("tools_registered", count=len(tools))

    # â”€â”€ ĞĞ³ĞµĞ½Ñ‚ / ĞÑ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ‚Ğ¾Ñ€ â”€â”€
    vram_manager = None

    if config.multi_agent_enabled:
        from core.orchestrator import Orchestrator

        agent = Orchestrator(
            tools=tools,
            memory=memory,
            identity=identity,
            vector_memory=vector_memory,
            thread_memory=thread_tracker,
        )

        vram_manager = getattr(agent, 'vram_manager', None)

        log.info("orchestrator_ready", agents=4)
    else:
        from core.agent import AgentCore
        agent = AgentCore(
            tools=tools,
            memory=memory,
            identity=identity,
            vector_memory=vector_memory,
            thread_memory=thread_tracker,
        )

    log.info("system_ready")

    return {
        "agent": agent,
        "memory": memory,
        "identity": identity,
        "emotions": emotion_analyzer,
        "vad_emotions": vad_emotions,
        "metacognition": metacognition,
        "self_awareness": self_awareness,
        "vector_memory": vector_memory,
        "embedding_cache": embedding_cache,
        "system_controller": system_controller,
        "vram_manager": vram_manager,
        "thread_tracker": thread_tracker,
        "context_compressor": context_compressor,
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                    ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ Ğ—ĞĞŸĞ ĞĞ¡ĞĞ’
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def process_input(user_input: str, components: dict) -> str:
    """ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ²Ğ²Ğ¾Ğ´ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ"""

    text = user_input.strip()
    text_lower = text.lower()

    # â”€â”€ Ğ¡Ğ¿ĞµÑ†ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ â”€â”€
    if text_lower in ("Ğ²Ñ‹Ñ…Ğ¾Ğ´", "exit", "quit", "Ğ¿Ğ¾ĞºĞ°"):
        print("\nğŸ’­ ĞšÑ€Ğ¸ÑÑ‚Ğ¸Ğ½Ğ°: ĞŸĞ¾ĞºĞ°! Ğ‘Ñ‹Ğ»Ğ¾ Ğ¿Ñ€Ğ¸ÑÑ‚Ğ½Ğ¾ Ğ¿Ğ¾Ğ¾Ğ±Ñ‰Ğ°Ñ‚ÑŒÑÑ.")
        return "EXIT"

    if text_lower in ("ÑÑ‚Ğ°Ñ‚ÑƒÑ", "status"):
        mem_stats = components["memory"].get_stats()
        w = mem_stats.get("working", 0)
        e = mem_stats.get("episodic", 0)
        s = mem_stats.get("semantic_keys", 0)

        status = f"ğŸ“Š ĞŸĞ°Ğ¼ÑÑ‚ÑŒ: Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ°Ñ {w} | ÑĞ¿Ğ¸Ğ·Ğ¾Ğ´Ñ‹ {e} | Ñ„Ğ°ĞºÑ‚Ñ‹ {s}"

        # v6.0: VAD + Self-Awareness
        vad = components.get("vad_emotions")
        if vad:
            vs = vad.state
            status += f"\nğŸ­ Ğ­Ğ¼Ğ¾Ñ†Ğ¸Ğ¸: {vs.label} (V:{vs.valence:.2f} A:{vs.arousal:.2f} D:{vs.dominance:.2f})"

        sa = components.get("self_awareness")
        if sa:
            status += f"\nğŸ§  {sa.get_self_description()}"

        mc = components.get("metacognition")
        if mc:
            intro = mc.introspect()
            status += f"\nğŸ” ĞšĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºĞ°: {intro['calibration']['calibration_error']:.2f} | ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ñ… Ñ‚ĞµĞ¼: {intro['known_unknowns']['count']}"

        return status

    if text_lower in ("Ğ¾Ñ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ", "clear memory"):
        components["memory"].clear_working()
        return "âœ… Ğ Ğ°Ğ±Ğ¾Ñ‡Ğ°Ñ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½Ğ°!"

    if text_lower in ("Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒ", "help"):
        return (
            "ğŸ“– ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹: ÑÑ‚Ğ°Ñ‚ÑƒÑ, Ğ¾Ñ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ, Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒ, Ğ²Ñ‹Ñ…Ğ¾Ğ´\n"
            "ğŸ’¡ ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹: Â«ÑƒĞ´Ğ°Ğ»Ğ¸ Ñ„Ğ°Ğ¹Ğ»Â», Â«Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸ ChromeÂ», Â«Ğ½Ğ°Ğ¹Ğ´Ğ¸ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸ÑÂ», Â«ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸Â»"
        )

    # â”€â”€ Ğ­Ğ¼Ğ¾Ñ†Ğ¸Ñ â”€â”€
    emotion = components["emotions"].analyze(text)
    components["identity"].increment_conversation_depth()

    # â”€â”€ ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ñ‡ĞµÑ€ĞµĞ· Ğ°Ğ³ĞµĞ½Ñ‚Ğ° â”€â”€
    had_errors = False
    try:
        response = await components["agent"].process(text)
    except Exception as exc:
        log.error("process_error", error=str(exc), exc_info=True)
        response = f"ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ¾ÑˆĞ»Ğ° Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {exc}"
        had_errors = True

    # â”€â”€ v6.0: ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ VAD ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¸, self-awareness, metacognition â”€â”€
    vad = components.get("vad_emotions")
    if vad:
        vad.update_from_dialogue(text, response, had_errors=had_errors)

    sa = components.get("self_awareness")
    if sa:
        user_happy = any(w in text.lower() for w in ["ÑĞ¿Ğ°ÑĞ¸Ğ±Ğ¾", "ĞºÑ€ÑƒÑ‚Ğ¾", "Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾", "Ğ¼Ğ¾Ğ»Ğ¾Ğ´ĞµÑ†"])
        user_angry = any(w in text.lower() for w in ["Ğ¾ÑˆĞ¸Ğ±ĞºĞ°", "Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚", "Ğ±Ñ€ĞµĞ´", "Ğ¾Ğ¿ÑÑ‚ÑŒ"])
        sa.update(
            valence=vad.state.valence if vad else 0.0,
            had_errors=had_errors,
            user_expressed_satisfaction=user_happy,
            user_expressed_frustration=user_angry,
        )

    mc = components.get("metacognition")
    if mc:
        mc.update_agency(not had_errors)

    return response


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                    Ğ“Ğ›ĞĞ’ĞĞ«Ğ™ Ğ¦Ğ˜ĞšĞ›
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def main():
    shutdown = GracefulShutdown()
    components = await initialize_system()

    print(f"\n{'=' * 60}")
    print(f"ğŸ’¬ ĞšÑ€Ğ¸ÑÑ‚Ğ¸Ğ½Ğ° 6.0 {'ğŸ¦€ Rust' if RUST_AVAILABLE else 'ğŸ Python'} | Ğ’Ğ²ĞµĞ´Ğ¸ 'Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒ'")
    print(f"{'=' * 60}\n")

    try:
        while not shutdown.should_exit:
            try:
                user_input = input("Ğ¢Ñ‹: ").strip()
                if not user_input:
                    continue

                response = await process_input(user_input, components)
                if response == "EXIT":
                    break

                print(f"ĞšÑ€Ğ¸ÑÑ‚Ğ¸Ğ½Ğ°: {response}\n")

            except KeyboardInterrupt:
                break
            except EOFError:
                break
            except Exception as exc:
                log.error("main_loop_error", error=str(exc))
                print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {exc}\n")

    finally:
        log.info("shutdown_start")

        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ
        components["memory"].save()
        components["embedding_cache"].save()

        # v6.0: ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ ĞºÑÑˆ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸
        if hasattr(components.get("vector_memory"), "save_cache"):
            components["vector_memory"].save_cache()

        # v6.0: ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ metacognition
        if components.get("metacognition"):
            components["metacognition"].save()

        if components["vram_manager"]:
            components["vram_manager"].cleanup()

        log.info("shutdown_complete")
        print("\nğŸ’­ Ğ”Ğ¾ Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ¸!")


if __name__ == "__main__":
    import platform
    
    # uvloop Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ Linux/macOS
    if platform.system() != "Windows":
        try:
            import uvloop
            uvloop.install()
            log.info("uvloop_installed")
        except ImportError:
            pass
    else:
        log.info("platform", os="Windows", event_loop="standard asyncio")

    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ’­ Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ğµ...")