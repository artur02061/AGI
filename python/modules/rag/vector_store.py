"""
–ö—Ä–∏—Å—Ç–∏–Ω–∞ 6.0 ‚Äî –í–µ–∫—Ç–æ—Ä–Ω–∞—è –ø–∞–º—è—Ç—å

–ò–ó–ú–ï–ù–ï–ù–ò–Ø v6.0:
- ‚úÖ PersistentClient –≤–º–µ—Å—Ç–æ in-memory Client (–¥–∞–Ω–Ω—ã–µ –ù–ï —Ç–µ—Ä—è—é—Ç—Å—è –ø—Ä–∏ —Ä–µ—Å—Ç–∞—Ä—Ç–µ!)
- ‚úÖ JSON –∫—ç—à –≤–º–µ—Å—Ç–æ pickle
- ‚úÖ Async-safe embedding —á–µ—Ä–µ–∑ ollama.AsyncClient
- ‚úÖ Graceful fallback –µ—Å–ª–∏ ChromaDB –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
- ‚úÖ –£–±—Ä–∞–Ω –¥—É–±–ª–∏–∫–∞—Ç modules/rag/memory.py
"""

import json
import hashlib
import re
from collections import Counter
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional

import ollama

from utils.logging import get_logger
import config

logger = get_logger("vector_store")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#                   CHROMADB –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _init_chromadb(persist_dir: str):
    """
    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç ChromaDB —Å PersistentClient.
    Fallback –Ω–∞ in-memory –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫.
    """
    try:
        import chromadb
        from chromadb.config import Settings

        # v6.0: PersistentClient ‚Äî –¥–∞–Ω–Ω—ã–µ –Ω–∞ –¥–∏—Å–∫–µ!
        client = chromadb.PersistentClient(
            path=persist_dir,
            settings=Settings(anonymized_telemetry=False),
        )
        logger.info(f"‚úÖ ChromaDB PersistentClient: {persist_dir}")
        return client

    except TypeError:
        # –°—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è ChromaDB –±–µ–∑ PersistentClient
        import chromadb
        from chromadb.config import Settings

        client = chromadb.Client(Settings(
            persist_directory=persist_dir,
            chroma_db_impl="duckdb+parquet",
            anonymized_telemetry=False,
        ))
        logger.warning("‚ö†Ô∏è ChromaDB —Å—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º legacy persist")
        return client

    except ImportError:
        logger.error("‚ùå ChromaDB –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω! pip install chromadb")
        return None

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ ChromaDB: {e}")
        return None


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#                     VECTOR MEMORY
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class VectorMemory:
    """–í–µ–∫—Ç–æ—Ä–Ω–∞—è –ø–∞–º—è—Ç—å —Å –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ–º"""

    def __init__(self, persist_dir: str = None, shared_embedding_cache=None):
        persist_dir = persist_dir or str(config.VECTOR_DB_DIR)
        Path(persist_dir).mkdir(parents=True, exist_ok=True)

        self.client = _init_chromadb(persist_dir)
        self.collection = None

        if self.client is not None:
            try:
                self.collection = self.client.get_or_create_collection(
                    name="kristina_memory",
                    metadata={"hnsw:space": "cosine"},
                )
                logger.info("‚úÖ –ö–æ–ª–ª–µ–∫—Ü–∏—è kristina_memory –≥–æ—Ç–æ–≤–∞")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}")

        # Embedding –∫—ç—à ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â–∏–π –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω, –∏–Ω–∞—á–µ —Å–≤–æ–π
        self._shared_cache = shared_embedding_cache
        self.embedding_cache: Dict[str, List[float]] = {}
        self._cache_path = Path(config.DATA_DIR) / "embedding_cache.json"

        if self._shared_cache is None and config.EMBEDDING_CACHE_ENABLED:
            self._load_embedding_cache()

        # –°—á—ë—Ç—á–∏–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        self.doc_counter = 0
        if self.collection is not None:
            try:
                self.doc_counter = self.collection.count()
            except Exception:
                self.doc_counter = 0

        logger.info(f"üìä –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {self.doc_counter} | –ö—ç—à: {len(self.embedding_cache)}")

    # ‚îÄ‚îÄ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ ‚îÄ‚îÄ

    def add_dialogue(
        self,
        user_input: str,
        assistant_response: str,
        importance: int = 1,
        metadata: Optional[Dict] = None,
    ):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∏–∞–ª–æ–≥ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ø–∞–º—è—Ç—å"""
        if self.collection is None:
            logger.warning("‚ö†Ô∏è ChromaDB –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –¥–∏–∞–ª–æ–≥ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω")
            return

        text = f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_input}\n–ö—Ä–∏—Å—Ç–∏–Ω–∞: {assistant_response}"
        now = datetime.now()

        meta = {
            "type": "dialogue",
            "timestamp": now.isoformat(),
            "date": now.strftime("%Y-%m-%d"),
            "month": now.strftime("%Y-%m"),
            "time": now.strftime("%H:%M"),
            "importance": importance,
            "user_input": user_input[:200],
            "response_length": len(assistant_response),
            "keywords": json.dumps(self._extract_keywords(text), ensure_ascii=False),
            "category": self._classify_category(user_input),
        }
        if metadata:
            # ChromaDB –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –≤–ª–æ–∂–µ–Ω–Ω—ã–µ dict ‚Äî —Ç–æ–ª—å–∫–æ str/int/float
            for k, v in metadata.items():
                if isinstance(v, (str, int, float, bool)):
                    meta[k] = v
                else:
                    meta[k] = str(v)

        embedding = self._get_embedding(text)

        doc_id = f"dialogue_{self.doc_counter}"
        self.doc_counter += 1

        try:
            self.collection.add(
                ids=[doc_id],
                embeddings=[embedding],
                documents=[text],
                metadatas=[meta],
            )
            logger.debug(f"üíæ –î–∏–∞–ª–æ–≥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {doc_id}")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞: {e}")

    # ‚îÄ‚îÄ –ü–æ–∏—Å–∫ ‚îÄ‚îÄ

    def search(
        self,
        query: str,
        n_results: int = None,
        filter_metadata: Optional[Dict] = None,
        date_range: Optional[tuple] = None,
    ) -> List[Dict]:
        """–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏"""
        if self.collection is None:
            return []

        n_results = n_results or config.VECTOR_SEARCH_RESULTS

        query_embedding = self._get_embedding(query)

        where_filter = {}
        if filter_metadata:
            where_filter.update(filter_metadata)

        try:
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=min(n_results * 2, max(self.doc_counter, 1)),
                where=where_filter if where_filter else None,
            )
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            return []

        formatted = []
        if results["ids"] and results["ids"][0]:
            for i in range(len(results["ids"][0])):
                meta = results["metadatas"][0][i]
                result_date = meta.get("date", "")

                if date_range:
                    from_date, to_date = date_range
                    if not (from_date <= result_date <= to_date):
                        continue

                formatted.append({
                    "id": results["ids"][0][i],
                    "text": results["documents"][0][i],
                    "metadata": meta,
                    "distance": results["distances"][0][i] if "distances" in results else None,
                })

        formatted.sort(key=lambda x: (
            x["distance"] if x["distance"] is not None else 1.0,
            -x["metadata"].get("importance", 1),
        ))

        return formatted[:n_results]

    def search_by_timeframe(
        self,
        query: str,
        timeframe: str,
        n_results: int = None,
    ) -> List[Dict]:
        """–ü–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏"""
        now = datetime.now()
        timeframes = {
            "today": (now.strftime("%Y-%m-%d"), now.strftime("%Y-%m-%d")),
            "yesterday": (
                (now - timedelta(days=1)).strftime("%Y-%m-%d"),
                (now - timedelta(days=1)).strftime("%Y-%m-%d"),
            ),
            "this_week": (
                (now - timedelta(days=now.weekday())).strftime("%Y-%m-%d"),
                now.strftime("%Y-%m-%d"),
            ),
            "this_month": (
                now.replace(day=1).strftime("%Y-%m-%d"),
                now.strftime("%Y-%m-%d"),
            ),
        }
        date_range = timeframes.get(timeframe)
        return self.search(query, n_results=n_results, date_range=date_range)

    def get_recent_dialogues(self, n: int = 10) -> List[Dict]:
        """–ü–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–∏–∞–ª–æ–≥–æ–≤"""
        if self.collection is None:
            return []
        try:
            all_items = self.collection.get(
                where={"type": "dialogue"},
                include=["documents", "metadatas"],
            )
        except Exception:
            return []

        if not all_items["ids"]:
            return []

        items = []
        for i in range(len(all_items["ids"])):
            items.append({
                "id": all_items["ids"][i],
                "text": all_items["documents"][i],
                "metadata": all_items["metadatas"][i],
            })

        items.sort(key=lambda x: x["metadata"].get("timestamp", ""), reverse=True)
        return items[:n]

    # ‚îÄ‚îÄ Embeddings ‚îÄ‚îÄ

    def _get_embedding(self, text: str) -> List[float]:
        """–ü–æ–ª—É—á–∞–µ—Ç embedding —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º (—á–µ—Ä–µ–∑ shared –∏–ª–∏ local cache)"""
        # –ï—Å–ª–∏ –µ—Å—Ç—å shared cache (EmbeddingCacheAdapter) ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
        if self._shared_cache is not None:
            cached = self._shared_cache.get(text)
            if cached is not None:
                return cached

            try:
                response = ollama.embeddings(
                    model=config.EMBEDDING_MODEL,
                    prompt=text,
                )
                embedding = response["embedding"]
                self._shared_cache.put(text, embedding)
                return embedding
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ embedding: {e}")
                return [0.0] * config.EMBEDDING_DIM

        # Fallback: –ª–æ–∫–∞–ª—å–Ω—ã–π cache
        text_hash = hashlib.md5(text.encode()).hexdigest()

        if config.EMBEDDING_CACHE_ENABLED and text_hash in self.embedding_cache:
            return self.embedding_cache[text_hash]

        try:
            response = ollama.embeddings(
                model=config.EMBEDDING_MODEL,
                prompt=text,
            )
            embedding = response["embedding"]

            if config.EMBEDDING_CACHE_ENABLED:
                self.embedding_cache[text_hash] = embedding
                if len(self.embedding_cache) % 100 == 0:
                    self._save_embedding_cache()

            return embedding

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ embedding: {e}")
            return [0.0] * config.EMBEDDING_DIM

    async def _get_embedding_async(self, text: str) -> List[float]:
        """Async-safe embedding ‚Äî –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç event loop"""
        import asyncio
        return await asyncio.to_thread(self._get_embedding, text)

    def _load_embedding_cache(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç JSON –∫—ç—à"""
        if self._cache_path.exists():
            try:
                with open(self._cache_path, "r", encoding="utf-8") as f:
                    self.embedding_cache = json.load(f)
                logger.info(f"‚úÖ –ö—ç—à embeddings: {len(self.embedding_cache)} –∑–∞–ø–∏—Å–µ–π")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫—ç—à–∞: {e}")
                self.embedding_cache = {}

    def _save_embedding_cache(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç JSON –∫—ç—à"""
        try:
            if len(self.embedding_cache) > config.EMBEDDING_CACHE_MAX_SIZE:
                items = list(self.embedding_cache.items())
                self.embedding_cache = dict(items[-config.EMBEDDING_CACHE_MAX_SIZE:])

            with open(self._cache_path, "w") as f:
                json.dump(self.embedding_cache, f)
            logger.debug(f"üíæ –ö—ç—à: {len(self.embedding_cache)} –∑–∞–ø–∏—Å–µ–π")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—ç—à–∞: {e}")

    # ‚îÄ‚îÄ –£—Ç–∏–ª–∏—Ç—ã ‚îÄ‚îÄ

    @staticmethod
    def _extract_keywords(text: str) -> List[str]:
        stop_words = {
            "—è", "—Ç—ã", "–æ–Ω", "–æ–Ω–∞", "–º—ã", "–≤—ã", "–æ–Ω–∏",
            "–≤", "–Ω–∞", "–∏", "—Å", "–ø–æ", "–¥–ª—è", "–æ—Ç", "–∫",
            "the", "is", "are", "was", "were", "a", "an",
        }
        words = re.findall(r"\b\w+\b", text.lower())
        counter = Counter(w for w in words if len(w) > 3 and w not in stop_words)
        return [word for word, _ in counter.most_common(10)]

    @staticmethod
    def _classify_category(text: str) -> str:
        text_lower = text.lower()
        categories = {
            "code": ["–∫–æ–¥", "—Ñ—É–Ω–∫—Ü–∏—è", "–∫–ª–∞—Å—Å", "–æ—à–∏–±–∫–∞", "–ø—Ä–æ–≥—Ä–∞–º–º", "python"],
            "system": ["–∑–∞–ø—É—Å—Ç–∏", "–æ—Ç–∫—Ä–æ–π", "—Ñ–∞–π–ª", "–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ", "–ø—Ä–æ—Ü–µ—Å—Å"],
            "web": ["–Ω–∞–π–¥–∏", "–ø–æ–∏—Å–∫", "–∏–Ω—Ç–µ—Ä–Ω–µ—Ç", "–Ω–æ–≤–æ—Å—Ç–∏", "–ø–æ–≥–æ–¥–∞"],
            "personal": ["–ø–æ–º–Ω–∏—à—å", "–≥–æ–≤–æ—Ä–∏–ª", "–æ–±—Å—É–∂–¥–∞–ª–∏", "–Ω–∞–ø–æ–º–Ω–∏"],
        }
        for category, keywords in categories.items():
            if any(kw in text_lower for kw in keywords):
                return category
        return "general"

    def get_stats(self) -> Dict:
        total = self.doc_counter
        return {
            "total": total,
            "dialogues": total,  # –ü–æ–∫–∞ –≤—Å—ë ‚Äî –¥–∏–∞–ª–æ–≥–∏
            "cache_size": len(self.embedding_cache),
            "persistent": self.client is not None,
        }

    def save_cache(self):
        """–Ø–≤–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫—ç—à–∞ (–≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ shutdown)"""
        if config.EMBEDDING_CACHE_ENABLED:
            self._save_embedding_cache()
